{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOFO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8_T2LCfAN_XF"
   },
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "K1li4zpPN_XH"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Previous Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved Random Forest model\n",
    "model_folder = \"../../2_Modeling_Phase/Saved-Models/\"\n",
    "model_filename = \"Farm-Flow_XGBoost.joblib\"\n",
    "model_path = model_folder + model_filename\n",
    "\n",
    "model = joblib.load(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Train Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"../../0_Datasets/Farm-Flow/train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"../../0_Datasets/Farm-Flow/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fwd_pkts_tot</th>\n",
       "      <th>bwd_pkts_tot</th>\n",
       "      <th>fwd_data_pkts_tot</th>\n",
       "      <th>bwd_data_pkts_tot</th>\n",
       "      <th>fwd_pkts_per_sec</th>\n",
       "      <th>bwd_pkts_per_sec</th>\n",
       "      <th>flow_pkts_per_sec</th>\n",
       "      <th>down_up_ratio</th>\n",
       "      <th>fwd_header_size_tot</th>\n",
       "      <th>fwd_header_size_min</th>\n",
       "      <th>...</th>\n",
       "      <th>flow_pkts_payload.max</th>\n",
       "      <th>flow_pkts_payload.tot</th>\n",
       "      <th>flow_pkts_payload.avg</th>\n",
       "      <th>flow_pkts_payload.std</th>\n",
       "      <th>fwd_subflow_pkts</th>\n",
       "      <th>bwd_subflow_pkts</th>\n",
       "      <th>fwd_subflow_bytes</th>\n",
       "      <th>bwd_subflow_bytes</th>\n",
       "      <th>traffic</th>\n",
       "      <th>is_attack</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.236304</td>\n",
       "      <td>-0.662387</td>\n",
       "      <td>-0.577140</td>\n",
       "      <td>-0.443123</td>\n",
       "      <td>-0.277741</td>\n",
       "      <td>-0.268577</td>\n",
       "      <td>-0.273647</td>\n",
       "      <td>-1.394192</td>\n",
       "      <td>-0.643844</td>\n",
       "      <td>-1.423582</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.562720</td>\n",
       "      <td>-0.744570</td>\n",
       "      <td>-0.562649</td>\n",
       "      <td>-0.557806</td>\n",
       "      <td>-0.556874</td>\n",
       "      <td>-0.638986</td>\n",
       "      <td>-0.741186</td>\n",
       "      <td>-0.418623</td>\n",
       "      <td>UDP_Flood</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.672105</td>\n",
       "      <td>-0.457813</td>\n",
       "      <td>-0.577140</td>\n",
       "      <td>-0.443123</td>\n",
       "      <td>0.490111</td>\n",
       "      <td>0.504662</td>\n",
       "      <td>0.498222</td>\n",
       "      <td>0.728588</td>\n",
       "      <td>-0.643844</td>\n",
       "      <td>0.278456</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.562720</td>\n",
       "      <td>-0.744570</td>\n",
       "      <td>-0.562649</td>\n",
       "      <td>-0.557806</td>\n",
       "      <td>-0.556874</td>\n",
       "      <td>-0.419418</td>\n",
       "      <td>-0.741186</td>\n",
       "      <td>-0.418623</td>\n",
       "      <td>Port_Scanning</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.454205</td>\n",
       "      <td>-0.662387</td>\n",
       "      <td>-0.577140</td>\n",
       "      <td>-0.443123</td>\n",
       "      <td>-0.277918</td>\n",
       "      <td>-0.268577</td>\n",
       "      <td>-0.273736</td>\n",
       "      <td>-1.394192</td>\n",
       "      <td>-0.724235</td>\n",
       "      <td>-1.423582</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.562720</td>\n",
       "      <td>-0.744570</td>\n",
       "      <td>-0.562649</td>\n",
       "      <td>-0.557806</td>\n",
       "      <td>-0.556874</td>\n",
       "      <td>-0.638986</td>\n",
       "      <td>-0.741186</td>\n",
       "      <td>-0.418623</td>\n",
       "      <td>UDP_Flood</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.378496</td>\n",
       "      <td>2.406229</td>\n",
       "      <td>2.285759</td>\n",
       "      <td>2.444445</td>\n",
       "      <td>-0.276874</td>\n",
       "      <td>-0.267504</td>\n",
       "      <td>-0.272675</td>\n",
       "      <td>0.728588</td>\n",
       "      <td>2.129645</td>\n",
       "      <td>-0.147053</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.240860</td>\n",
       "      <td>1.678331</td>\n",
       "      <td>-0.105550</td>\n",
       "      <td>-0.268638</td>\n",
       "      <td>2.620142</td>\n",
       "      <td>2.654541</td>\n",
       "      <td>1.265201</td>\n",
       "      <td>2.728235</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.672105</td>\n",
       "      <td>-0.457813</td>\n",
       "      <td>-0.577140</td>\n",
       "      <td>-0.443123</td>\n",
       "      <td>-0.277823</td>\n",
       "      <td>-0.268460</td>\n",
       "      <td>-0.273629</td>\n",
       "      <td>0.728588</td>\n",
       "      <td>-0.684039</td>\n",
       "      <td>-0.147053</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.562720</td>\n",
       "      <td>-0.744570</td>\n",
       "      <td>-0.562649</td>\n",
       "      <td>-0.557806</td>\n",
       "      <td>-0.670339</td>\n",
       "      <td>-0.529202</td>\n",
       "      <td>-0.741186</td>\n",
       "      <td>-0.418623</td>\n",
       "      <td>MQTT_Flood</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47341</th>\n",
       "      <td>-0.454205</td>\n",
       "      <td>-0.457813</td>\n",
       "      <td>-0.577140</td>\n",
       "      <td>-0.443123</td>\n",
       "      <td>-0.276776</td>\n",
       "      <td>-0.267991</td>\n",
       "      <td>-0.272869</td>\n",
       "      <td>-0.332802</td>\n",
       "      <td>-0.483062</td>\n",
       "      <td>-0.147053</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.562720</td>\n",
       "      <td>-0.744570</td>\n",
       "      <td>-0.562649</td>\n",
       "      <td>-0.557806</td>\n",
       "      <td>-0.329944</td>\n",
       "      <td>-0.419418</td>\n",
       "      <td>-0.741186</td>\n",
       "      <td>-0.418623</td>\n",
       "      <td>TCP_Flood</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47342</th>\n",
       "      <td>-0.454205</td>\n",
       "      <td>-0.662387</td>\n",
       "      <td>-0.577140</td>\n",
       "      <td>-0.443123</td>\n",
       "      <td>-0.277509</td>\n",
       "      <td>-0.268577</td>\n",
       "      <td>-0.273530</td>\n",
       "      <td>-1.394192</td>\n",
       "      <td>-0.724235</td>\n",
       "      <td>-1.423582</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.562720</td>\n",
       "      <td>-0.744570</td>\n",
       "      <td>-0.562649</td>\n",
       "      <td>-0.557806</td>\n",
       "      <td>-0.556874</td>\n",
       "      <td>-0.638986</td>\n",
       "      <td>-0.741186</td>\n",
       "      <td>-0.418623</td>\n",
       "      <td>UDP_Flood</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47343</th>\n",
       "      <td>2.160596</td>\n",
       "      <td>1.997080</td>\n",
       "      <td>2.285759</td>\n",
       "      <td>2.444445</td>\n",
       "      <td>-0.276943</td>\n",
       "      <td>-0.267646</td>\n",
       "      <td>-0.272781</td>\n",
       "      <td>0.576960</td>\n",
       "      <td>1.928668</td>\n",
       "      <td>-0.147053</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.240860</td>\n",
       "      <td>1.678331</td>\n",
       "      <td>-0.054762</td>\n",
       "      <td>-0.267306</td>\n",
       "      <td>0.275202</td>\n",
       "      <td>0.312477</td>\n",
       "      <td>-0.072391</td>\n",
       "      <td>0.630330</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47344</th>\n",
       "      <td>1.288996</td>\n",
       "      <td>1.383357</td>\n",
       "      <td>1.713179</td>\n",
       "      <td>0.711904</td>\n",
       "      <td>-0.265775</td>\n",
       "      <td>-0.256330</td>\n",
       "      <td>-0.261520</td>\n",
       "      <td>0.728588</td>\n",
       "      <td>2.330623</td>\n",
       "      <td>1.129475</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.250326</td>\n",
       "      <td>0.400251</td>\n",
       "      <td>-0.238680</td>\n",
       "      <td>-0.346375</td>\n",
       "      <td>1.485493</td>\n",
       "      <td>1.556699</td>\n",
       "      <td>0.470671</td>\n",
       "      <td>0.378581</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47345</th>\n",
       "      <td>-0.672105</td>\n",
       "      <td>-0.457813</td>\n",
       "      <td>-0.577140</td>\n",
       "      <td>-0.443123</td>\n",
       "      <td>-0.277865</td>\n",
       "      <td>-0.268501</td>\n",
       "      <td>-0.273671</td>\n",
       "      <td>0.728588</td>\n",
       "      <td>-0.684039</td>\n",
       "      <td>-0.147053</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.562720</td>\n",
       "      <td>-0.744570</td>\n",
       "      <td>-0.562649</td>\n",
       "      <td>-0.557806</td>\n",
       "      <td>-0.670339</td>\n",
       "      <td>-0.529202</td>\n",
       "      <td>-0.741186</td>\n",
       "      <td>-0.418623</td>\n",
       "      <td>MQTT_Flood</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47346 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       fwd_pkts_tot  bwd_pkts_tot  fwd_data_pkts_tot  bwd_data_pkts_tot  \\\n",
       "0         -0.236304     -0.662387          -0.577140          -0.443123   \n",
       "1         -0.672105     -0.457813          -0.577140          -0.443123   \n",
       "2         -0.454205     -0.662387          -0.577140          -0.443123   \n",
       "3          2.378496      2.406229           2.285759           2.444445   \n",
       "4         -0.672105     -0.457813          -0.577140          -0.443123   \n",
       "...             ...           ...                ...                ...   \n",
       "47341     -0.454205     -0.457813          -0.577140          -0.443123   \n",
       "47342     -0.454205     -0.662387          -0.577140          -0.443123   \n",
       "47343      2.160596      1.997080           2.285759           2.444445   \n",
       "47344      1.288996      1.383357           1.713179           0.711904   \n",
       "47345     -0.672105     -0.457813          -0.577140          -0.443123   \n",
       "\n",
       "       fwd_pkts_per_sec  bwd_pkts_per_sec  flow_pkts_per_sec  down_up_ratio  \\\n",
       "0             -0.277741         -0.268577          -0.273647      -1.394192   \n",
       "1              0.490111          0.504662           0.498222       0.728588   \n",
       "2             -0.277918         -0.268577          -0.273736      -1.394192   \n",
       "3             -0.276874         -0.267504          -0.272675       0.728588   \n",
       "4             -0.277823         -0.268460          -0.273629       0.728588   \n",
       "...                 ...               ...                ...            ...   \n",
       "47341         -0.276776         -0.267991          -0.272869      -0.332802   \n",
       "47342         -0.277509         -0.268577          -0.273530      -1.394192   \n",
       "47343         -0.276943         -0.267646          -0.272781       0.576960   \n",
       "47344         -0.265775         -0.256330          -0.261520       0.728588   \n",
       "47345         -0.277865         -0.268501          -0.273671       0.728588   \n",
       "\n",
       "       fwd_header_size_tot  fwd_header_size_min  ...  flow_pkts_payload.max  \\\n",
       "0                -0.643844            -1.423582  ...              -0.562720   \n",
       "1                -0.643844             0.278456  ...              -0.562720   \n",
       "2                -0.724235            -1.423582  ...              -0.562720   \n",
       "3                 2.129645            -0.147053  ...              -0.240860   \n",
       "4                -0.684039            -0.147053  ...              -0.562720   \n",
       "...                    ...                  ...  ...                    ...   \n",
       "47341            -0.483062            -0.147053  ...              -0.562720   \n",
       "47342            -0.724235            -1.423582  ...              -0.562720   \n",
       "47343             1.928668            -0.147053  ...              -0.240860   \n",
       "47344             2.330623             1.129475  ...              -0.250326   \n",
       "47345            -0.684039            -0.147053  ...              -0.562720   \n",
       "\n",
       "       flow_pkts_payload.tot  flow_pkts_payload.avg  flow_pkts_payload.std  \\\n",
       "0                  -0.744570              -0.562649              -0.557806   \n",
       "1                  -0.744570              -0.562649              -0.557806   \n",
       "2                  -0.744570              -0.562649              -0.557806   \n",
       "3                   1.678331              -0.105550              -0.268638   \n",
       "4                  -0.744570              -0.562649              -0.557806   \n",
       "...                      ...                    ...                    ...   \n",
       "47341              -0.744570              -0.562649              -0.557806   \n",
       "47342              -0.744570              -0.562649              -0.557806   \n",
       "47343               1.678331              -0.054762              -0.267306   \n",
       "47344               0.400251              -0.238680              -0.346375   \n",
       "47345              -0.744570              -0.562649              -0.557806   \n",
       "\n",
       "       fwd_subflow_pkts  bwd_subflow_pkts  fwd_subflow_bytes  \\\n",
       "0             -0.556874         -0.638986          -0.741186   \n",
       "1             -0.556874         -0.419418          -0.741186   \n",
       "2             -0.556874         -0.638986          -0.741186   \n",
       "3              2.620142          2.654541           1.265201   \n",
       "4             -0.670339         -0.529202          -0.741186   \n",
       "...                 ...               ...                ...   \n",
       "47341         -0.329944         -0.419418          -0.741186   \n",
       "47342         -0.556874         -0.638986          -0.741186   \n",
       "47343          0.275202          0.312477          -0.072391   \n",
       "47344          1.485493          1.556699           0.470671   \n",
       "47345         -0.670339         -0.529202          -0.741186   \n",
       "\n",
       "       bwd_subflow_bytes        traffic  is_attack  \n",
       "0              -0.418623      UDP_Flood          1  \n",
       "1              -0.418623  Port_Scanning          1  \n",
       "2              -0.418623      UDP_Flood          1  \n",
       "3               2.728235         Normal          0  \n",
       "4              -0.418623     MQTT_Flood          1  \n",
       "...                  ...            ...        ...  \n",
       "47341          -0.418623      TCP_Flood          1  \n",
       "47342          -0.418623      UDP_Flood          1  \n",
       "47343           0.630330         Normal          0  \n",
       "47344           0.378581         Normal          0  \n",
       "47345          -0.418623     MQTT_Flood          1  \n",
       "\n",
       "[47346 rows x 35 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fwd_pkts_tot</th>\n",
       "      <th>bwd_pkts_tot</th>\n",
       "      <th>fwd_data_pkts_tot</th>\n",
       "      <th>bwd_data_pkts_tot</th>\n",
       "      <th>fwd_pkts_per_sec</th>\n",
       "      <th>bwd_pkts_per_sec</th>\n",
       "      <th>flow_pkts_per_sec</th>\n",
       "      <th>down_up_ratio</th>\n",
       "      <th>fwd_header_size_tot</th>\n",
       "      <th>fwd_header_size_min</th>\n",
       "      <th>...</th>\n",
       "      <th>flow_pkts_payload.max</th>\n",
       "      <th>flow_pkts_payload.tot</th>\n",
       "      <th>flow_pkts_payload.avg</th>\n",
       "      <th>flow_pkts_payload.std</th>\n",
       "      <th>fwd_subflow_pkts</th>\n",
       "      <th>bwd_subflow_pkts</th>\n",
       "      <th>fwd_subflow_bytes</th>\n",
       "      <th>bwd_subflow_bytes</th>\n",
       "      <th>traffic</th>\n",
       "      <th>is_attack</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.672105</td>\n",
       "      <td>-0.457813</td>\n",
       "      <td>-0.577140</td>\n",
       "      <td>-0.443123</td>\n",
       "      <td>-0.276940</td>\n",
       "      <td>-0.267571</td>\n",
       "      <td>-0.272742</td>\n",
       "      <td>0.728588</td>\n",
       "      <td>-0.684039</td>\n",
       "      <td>-0.147053</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.562720</td>\n",
       "      <td>-0.744570</td>\n",
       "      <td>-0.562649</td>\n",
       "      <td>-0.557806</td>\n",
       "      <td>-0.556874</td>\n",
       "      <td>-0.419418</td>\n",
       "      <td>-0.741186</td>\n",
       "      <td>-0.418623</td>\n",
       "      <td>MQTT_Flood</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.672105</td>\n",
       "      <td>-0.457813</td>\n",
       "      <td>-0.577140</td>\n",
       "      <td>-0.443123</td>\n",
       "      <td>-0.277181</td>\n",
       "      <td>-0.267813</td>\n",
       "      <td>-0.272983</td>\n",
       "      <td>0.728588</td>\n",
       "      <td>-0.684039</td>\n",
       "      <td>-0.147053</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.562720</td>\n",
       "      <td>-0.744570</td>\n",
       "      <td>-0.562649</td>\n",
       "      <td>-0.557806</td>\n",
       "      <td>-0.556874</td>\n",
       "      <td>-0.419418</td>\n",
       "      <td>-0.741186</td>\n",
       "      <td>-0.418623</td>\n",
       "      <td>MQTT_Flood</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.454205</td>\n",
       "      <td>-0.457813</td>\n",
       "      <td>-0.577140</td>\n",
       "      <td>-0.443123</td>\n",
       "      <td>-0.276909</td>\n",
       "      <td>-0.268058</td>\n",
       "      <td>-0.272969</td>\n",
       "      <td>-0.332802</td>\n",
       "      <td>-0.483062</td>\n",
       "      <td>-0.147053</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.562720</td>\n",
       "      <td>-0.744570</td>\n",
       "      <td>-0.562649</td>\n",
       "      <td>-0.557806</td>\n",
       "      <td>-0.329944</td>\n",
       "      <td>-0.419418</td>\n",
       "      <td>-0.741186</td>\n",
       "      <td>-0.418623</td>\n",
       "      <td>TCP_Flood</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.378496</td>\n",
       "      <td>2.406229</td>\n",
       "      <td>2.285759</td>\n",
       "      <td>2.444445</td>\n",
       "      <td>-0.276907</td>\n",
       "      <td>-0.267537</td>\n",
       "      <td>-0.272708</td>\n",
       "      <td>0.728588</td>\n",
       "      <td>2.129645</td>\n",
       "      <td>-0.147053</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.240860</td>\n",
       "      <td>1.678331</td>\n",
       "      <td>-0.105550</td>\n",
       "      <td>-0.268638</td>\n",
       "      <td>2.620142</td>\n",
       "      <td>2.654541</td>\n",
       "      <td>1.265201</td>\n",
       "      <td>2.728235</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.454205</td>\n",
       "      <td>-0.253238</td>\n",
       "      <td>-0.004560</td>\n",
       "      <td>-0.443123</td>\n",
       "      <td>-0.276892</td>\n",
       "      <td>-0.267522</td>\n",
       "      <td>-0.272693</td>\n",
       "      <td>0.728588</td>\n",
       "      <td>-0.241889</td>\n",
       "      <td>1.129475</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.477522</td>\n",
       "      <td>-0.635539</td>\n",
       "      <td>-0.408378</td>\n",
       "      <td>-0.455263</td>\n",
       "      <td>-0.329944</td>\n",
       "      <td>-0.199849</td>\n",
       "      <td>-0.596727</td>\n",
       "      <td>-0.418623</td>\n",
       "      <td>HTTP_Flood</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15778</th>\n",
       "      <td>1.942696</td>\n",
       "      <td>2.201655</td>\n",
       "      <td>2.285759</td>\n",
       "      <td>2.444445</td>\n",
       "      <td>-0.277003</td>\n",
       "      <td>-0.267561</td>\n",
       "      <td>-0.272768</td>\n",
       "      <td>0.891878</td>\n",
       "      <td>1.727690</td>\n",
       "      <td>-0.147053</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.240860</td>\n",
       "      <td>1.678331</td>\n",
       "      <td>-0.054762</td>\n",
       "      <td>-0.267306</td>\n",
       "      <td>0.691239</td>\n",
       "      <td>0.897993</td>\n",
       "      <td>0.262007</td>\n",
       "      <td>1.154806</td>\n",
       "      <td>Arp_Spoofing</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15779</th>\n",
       "      <td>2.160596</td>\n",
       "      <td>2.201655</td>\n",
       "      <td>2.285759</td>\n",
       "      <td>2.444445</td>\n",
       "      <td>-0.276991</td>\n",
       "      <td>-0.267622</td>\n",
       "      <td>-0.272793</td>\n",
       "      <td>0.728588</td>\n",
       "      <td>1.928668</td>\n",
       "      <td>-0.147053</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.240860</td>\n",
       "      <td>1.678331</td>\n",
       "      <td>-0.072901</td>\n",
       "      <td>-0.267431</td>\n",
       "      <td>2.393212</td>\n",
       "      <td>2.434972</td>\n",
       "      <td>1.265201</td>\n",
       "      <td>2.728235</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15780</th>\n",
       "      <td>-0.236304</td>\n",
       "      <td>-0.662387</td>\n",
       "      <td>-0.577140</td>\n",
       "      <td>-0.443123</td>\n",
       "      <td>-0.277906</td>\n",
       "      <td>-0.268577</td>\n",
       "      <td>-0.273730</td>\n",
       "      <td>-1.394192</td>\n",
       "      <td>-0.643844</td>\n",
       "      <td>-1.423582</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.562720</td>\n",
       "      <td>-0.744570</td>\n",
       "      <td>-0.562649</td>\n",
       "      <td>-0.557806</td>\n",
       "      <td>-0.556874</td>\n",
       "      <td>-0.638986</td>\n",
       "      <td>-0.741186</td>\n",
       "      <td>-0.418623</td>\n",
       "      <td>UDP_Flood</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15781</th>\n",
       "      <td>-0.454205</td>\n",
       "      <td>-0.662387</td>\n",
       "      <td>-0.577140</td>\n",
       "      <td>-0.443123</td>\n",
       "      <td>-0.277687</td>\n",
       "      <td>-0.268577</td>\n",
       "      <td>-0.273620</td>\n",
       "      <td>-1.394192</td>\n",
       "      <td>-0.724235</td>\n",
       "      <td>-1.423582</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.562720</td>\n",
       "      <td>-0.744570</td>\n",
       "      <td>-0.562649</td>\n",
       "      <td>-0.557806</td>\n",
       "      <td>-0.556874</td>\n",
       "      <td>-0.638986</td>\n",
       "      <td>-0.741186</td>\n",
       "      <td>-0.418623</td>\n",
       "      <td>UDP_Flood</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15782</th>\n",
       "      <td>-0.236304</td>\n",
       "      <td>-0.662387</td>\n",
       "      <td>-0.577140</td>\n",
       "      <td>-0.443123</td>\n",
       "      <td>-0.277882</td>\n",
       "      <td>-0.268577</td>\n",
       "      <td>-0.273718</td>\n",
       "      <td>-1.394192</td>\n",
       "      <td>-0.643844</td>\n",
       "      <td>-1.423582</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.562720</td>\n",
       "      <td>-0.744570</td>\n",
       "      <td>-0.562649</td>\n",
       "      <td>-0.557806</td>\n",
       "      <td>-0.556874</td>\n",
       "      <td>-0.638986</td>\n",
       "      <td>-0.741186</td>\n",
       "      <td>-0.418623</td>\n",
       "      <td>UDP_Flood</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15783 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       fwd_pkts_tot  bwd_pkts_tot  fwd_data_pkts_tot  bwd_data_pkts_tot  \\\n",
       "0         -0.672105     -0.457813          -0.577140          -0.443123   \n",
       "1         -0.672105     -0.457813          -0.577140          -0.443123   \n",
       "2         -0.454205     -0.457813          -0.577140          -0.443123   \n",
       "3          2.378496      2.406229           2.285759           2.444445   \n",
       "4         -0.454205     -0.253238          -0.004560          -0.443123   \n",
       "...             ...           ...                ...                ...   \n",
       "15778      1.942696      2.201655           2.285759           2.444445   \n",
       "15779      2.160596      2.201655           2.285759           2.444445   \n",
       "15780     -0.236304     -0.662387          -0.577140          -0.443123   \n",
       "15781     -0.454205     -0.662387          -0.577140          -0.443123   \n",
       "15782     -0.236304     -0.662387          -0.577140          -0.443123   \n",
       "\n",
       "       fwd_pkts_per_sec  bwd_pkts_per_sec  flow_pkts_per_sec  down_up_ratio  \\\n",
       "0             -0.276940         -0.267571          -0.272742       0.728588   \n",
       "1             -0.277181         -0.267813          -0.272983       0.728588   \n",
       "2             -0.276909         -0.268058          -0.272969      -0.332802   \n",
       "3             -0.276907         -0.267537          -0.272708       0.728588   \n",
       "4             -0.276892         -0.267522          -0.272693       0.728588   \n",
       "...                 ...               ...                ...            ...   \n",
       "15778         -0.277003         -0.267561          -0.272768       0.891878   \n",
       "15779         -0.276991         -0.267622          -0.272793       0.728588   \n",
       "15780         -0.277906         -0.268577          -0.273730      -1.394192   \n",
       "15781         -0.277687         -0.268577          -0.273620      -1.394192   \n",
       "15782         -0.277882         -0.268577          -0.273718      -1.394192   \n",
       "\n",
       "       fwd_header_size_tot  fwd_header_size_min  ...  flow_pkts_payload.max  \\\n",
       "0                -0.684039            -0.147053  ...              -0.562720   \n",
       "1                -0.684039            -0.147053  ...              -0.562720   \n",
       "2                -0.483062            -0.147053  ...              -0.562720   \n",
       "3                 2.129645            -0.147053  ...              -0.240860   \n",
       "4                -0.241889             1.129475  ...              -0.477522   \n",
       "...                    ...                  ...  ...                    ...   \n",
       "15778             1.727690            -0.147053  ...              -0.240860   \n",
       "15779             1.928668            -0.147053  ...              -0.240860   \n",
       "15780            -0.643844            -1.423582  ...              -0.562720   \n",
       "15781            -0.724235            -1.423582  ...              -0.562720   \n",
       "15782            -0.643844            -1.423582  ...              -0.562720   \n",
       "\n",
       "       flow_pkts_payload.tot  flow_pkts_payload.avg  flow_pkts_payload.std  \\\n",
       "0                  -0.744570              -0.562649              -0.557806   \n",
       "1                  -0.744570              -0.562649              -0.557806   \n",
       "2                  -0.744570              -0.562649              -0.557806   \n",
       "3                   1.678331              -0.105550              -0.268638   \n",
       "4                  -0.635539              -0.408378              -0.455263   \n",
       "...                      ...                    ...                    ...   \n",
       "15778               1.678331              -0.054762              -0.267306   \n",
       "15779               1.678331              -0.072901              -0.267431   \n",
       "15780              -0.744570              -0.562649              -0.557806   \n",
       "15781              -0.744570              -0.562649              -0.557806   \n",
       "15782              -0.744570              -0.562649              -0.557806   \n",
       "\n",
       "       fwd_subflow_pkts  bwd_subflow_pkts  fwd_subflow_bytes  \\\n",
       "0             -0.556874         -0.419418          -0.741186   \n",
       "1             -0.556874         -0.419418          -0.741186   \n",
       "2             -0.329944         -0.419418          -0.741186   \n",
       "3              2.620142          2.654541           1.265201   \n",
       "4             -0.329944         -0.199849          -0.596727   \n",
       "...                 ...               ...                ...   \n",
       "15778          0.691239          0.897993           0.262007   \n",
       "15779          2.393212          2.434972           1.265201   \n",
       "15780         -0.556874         -0.638986          -0.741186   \n",
       "15781         -0.556874         -0.638986          -0.741186   \n",
       "15782         -0.556874         -0.638986          -0.741186   \n",
       "\n",
       "       bwd_subflow_bytes       traffic  is_attack  \n",
       "0              -0.418623    MQTT_Flood          1  \n",
       "1              -0.418623    MQTT_Flood          1  \n",
       "2              -0.418623     TCP_Flood          1  \n",
       "3               2.728235        Normal          0  \n",
       "4              -0.418623    HTTP_Flood          1  \n",
       "...                  ...           ...        ...  \n",
       "15778           1.154806  Arp_Spoofing          1  \n",
       "15779           2.728235        Normal          0  \n",
       "15780          -0.418623     UDP_Flood          1  \n",
       "15781          -0.418623     UDP_Flood          1  \n",
       "15782          -0.418623     UDP_Flood          1  \n",
       "\n",
       "[15783 rows x 35 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "## Train and Test Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop Multiclass Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.drop('traffic', axis=1)\n",
    "df_test = df_test.drop('traffic', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excluding the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_columns = df_train.columns.drop('is_attack')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a feature matrix X by selecting only the columns specified in X_columns. Then convert the selected data into a NumPy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train[X_columns].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creates a target variable y containing the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_train[\"is_attack\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get Features Names and Class Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = list(X_columns)\n",
    "class_names = [\"Normal\", \"Malicious\"]\n",
    "response_dict = {0: 'Normal', 1: 'Malicious'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Labeled Df's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_labeled = pd.DataFrame(X_test, columns=feature_names)\n",
    "X_train_labeled = pd.DataFrame(X_train, columns=feature_names)\n",
    "\n",
    "# Since both are one-dimensional NumPy arrays\n",
    "pred_series = pd.Series(pred)\n",
    "y_test_target_series = pd.Series(y_test)\n",
    "y_train_target_series = pd.Series(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a subset of the Train DF for faster training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_percentage = 0.1\n",
    "X_subset, _, y_subset, _ = train_test_split(X_train, y_train, test_size=1 - subset_percentage, stratify=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_percentage = 0.1\n",
    "X_subset_labeled, _, y_subset_labeled, _ = train_test_split(X_train_labeled, y_train_target_series, test_size=1 - subset_percentage, stratify=y_train_target_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Row to explain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## LOFO (Leave One Feature Out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How it works\n",
    "LOFO (Leave One Feature Out) Importance calculates the importances of a set of features based on a metric of choice, for a model of choice, by iteratively removing each feature from the set, and evaluating the performance of the model, with a validation scheme of choice, based on the chosen metric.\n",
    "\n",
    "LOFO first evaluates the performance of the model with all the input features included, then iteratively removes one feature at a time, retrains the model, and evaluates its performance on a validation set. The mean and standard deviation (across the folds) of the importance of each feature is then reported.\n",
    "\n",
    "If a model is not passed as an argument to LOFO Importance, it will run LightGBM as a default model.\n",
    "\n",
    "### How it applys\n",
    "Understand the feature importance of the dataset\n",
    "\n",
    "### Repository:\n",
    "- https://github.com/aerdem4/lofo-importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install lofo-importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fwd_pkts_tot</th>\n",
       "      <th>bwd_pkts_tot</th>\n",
       "      <th>fwd_data_pkts_tot</th>\n",
       "      <th>bwd_data_pkts_tot</th>\n",
       "      <th>fwd_pkts_per_sec</th>\n",
       "      <th>bwd_pkts_per_sec</th>\n",
       "      <th>flow_pkts_per_sec</th>\n",
       "      <th>down_up_ratio</th>\n",
       "      <th>fwd_header_size_tot</th>\n",
       "      <th>fwd_header_size_min</th>\n",
       "      <th>...</th>\n",
       "      <th>flow_pkts_payload.min</th>\n",
       "      <th>flow_pkts_payload.max</th>\n",
       "      <th>flow_pkts_payload.tot</th>\n",
       "      <th>flow_pkts_payload.avg</th>\n",
       "      <th>flow_pkts_payload.std</th>\n",
       "      <th>fwd_subflow_pkts</th>\n",
       "      <th>bwd_subflow_pkts</th>\n",
       "      <th>fwd_subflow_bytes</th>\n",
       "      <th>bwd_subflow_bytes</th>\n",
       "      <th>is_attack</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.236304</td>\n",
       "      <td>-0.662387</td>\n",
       "      <td>-0.577140</td>\n",
       "      <td>-0.443123</td>\n",
       "      <td>-0.277741</td>\n",
       "      <td>-0.268577</td>\n",
       "      <td>-0.273647</td>\n",
       "      <td>-1.394192</td>\n",
       "      <td>-0.643844</td>\n",
       "      <td>-1.423582</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.022646</td>\n",
       "      <td>-0.562720</td>\n",
       "      <td>-0.744570</td>\n",
       "      <td>-0.562649</td>\n",
       "      <td>-0.557806</td>\n",
       "      <td>-0.556874</td>\n",
       "      <td>-0.638986</td>\n",
       "      <td>-0.741186</td>\n",
       "      <td>-0.418623</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.672105</td>\n",
       "      <td>-0.457813</td>\n",
       "      <td>-0.577140</td>\n",
       "      <td>-0.443123</td>\n",
       "      <td>0.490111</td>\n",
       "      <td>0.504662</td>\n",
       "      <td>0.498222</td>\n",
       "      <td>0.728588</td>\n",
       "      <td>-0.643844</td>\n",
       "      <td>0.278456</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.022646</td>\n",
       "      <td>-0.562720</td>\n",
       "      <td>-0.744570</td>\n",
       "      <td>-0.562649</td>\n",
       "      <td>-0.557806</td>\n",
       "      <td>-0.556874</td>\n",
       "      <td>-0.419418</td>\n",
       "      <td>-0.741186</td>\n",
       "      <td>-0.418623</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.454205</td>\n",
       "      <td>-0.662387</td>\n",
       "      <td>-0.577140</td>\n",
       "      <td>-0.443123</td>\n",
       "      <td>-0.277918</td>\n",
       "      <td>-0.268577</td>\n",
       "      <td>-0.273736</td>\n",
       "      <td>-1.394192</td>\n",
       "      <td>-0.724235</td>\n",
       "      <td>-1.423582</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.022646</td>\n",
       "      <td>-0.562720</td>\n",
       "      <td>-0.744570</td>\n",
       "      <td>-0.562649</td>\n",
       "      <td>-0.557806</td>\n",
       "      <td>-0.556874</td>\n",
       "      <td>-0.638986</td>\n",
       "      <td>-0.741186</td>\n",
       "      <td>-0.418623</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.378496</td>\n",
       "      <td>2.406229</td>\n",
       "      <td>2.285759</td>\n",
       "      <td>2.444445</td>\n",
       "      <td>-0.276874</td>\n",
       "      <td>-0.267504</td>\n",
       "      <td>-0.272675</td>\n",
       "      <td>0.728588</td>\n",
       "      <td>2.129645</td>\n",
       "      <td>-0.147053</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.022646</td>\n",
       "      <td>-0.240860</td>\n",
       "      <td>1.678331</td>\n",
       "      <td>-0.105550</td>\n",
       "      <td>-0.268638</td>\n",
       "      <td>2.620142</td>\n",
       "      <td>2.654541</td>\n",
       "      <td>1.265201</td>\n",
       "      <td>2.728235</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.672105</td>\n",
       "      <td>-0.457813</td>\n",
       "      <td>-0.577140</td>\n",
       "      <td>-0.443123</td>\n",
       "      <td>-0.277823</td>\n",
       "      <td>-0.268460</td>\n",
       "      <td>-0.273629</td>\n",
       "      <td>0.728588</td>\n",
       "      <td>-0.684039</td>\n",
       "      <td>-0.147053</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.022646</td>\n",
       "      <td>-0.562720</td>\n",
       "      <td>-0.744570</td>\n",
       "      <td>-0.562649</td>\n",
       "      <td>-0.557806</td>\n",
       "      <td>-0.670339</td>\n",
       "      <td>-0.529202</td>\n",
       "      <td>-0.741186</td>\n",
       "      <td>-0.418623</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47341</th>\n",
       "      <td>-0.454205</td>\n",
       "      <td>-0.457813</td>\n",
       "      <td>-0.577140</td>\n",
       "      <td>-0.443123</td>\n",
       "      <td>-0.276776</td>\n",
       "      <td>-0.267991</td>\n",
       "      <td>-0.272869</td>\n",
       "      <td>-0.332802</td>\n",
       "      <td>-0.483062</td>\n",
       "      <td>-0.147053</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.022646</td>\n",
       "      <td>-0.562720</td>\n",
       "      <td>-0.744570</td>\n",
       "      <td>-0.562649</td>\n",
       "      <td>-0.557806</td>\n",
       "      <td>-0.329944</td>\n",
       "      <td>-0.419418</td>\n",
       "      <td>-0.741186</td>\n",
       "      <td>-0.418623</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47342</th>\n",
       "      <td>-0.454205</td>\n",
       "      <td>-0.662387</td>\n",
       "      <td>-0.577140</td>\n",
       "      <td>-0.443123</td>\n",
       "      <td>-0.277509</td>\n",
       "      <td>-0.268577</td>\n",
       "      <td>-0.273530</td>\n",
       "      <td>-1.394192</td>\n",
       "      <td>-0.724235</td>\n",
       "      <td>-1.423582</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.022646</td>\n",
       "      <td>-0.562720</td>\n",
       "      <td>-0.744570</td>\n",
       "      <td>-0.562649</td>\n",
       "      <td>-0.557806</td>\n",
       "      <td>-0.556874</td>\n",
       "      <td>-0.638986</td>\n",
       "      <td>-0.741186</td>\n",
       "      <td>-0.418623</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47343</th>\n",
       "      <td>2.160596</td>\n",
       "      <td>1.997080</td>\n",
       "      <td>2.285759</td>\n",
       "      <td>2.444445</td>\n",
       "      <td>-0.276943</td>\n",
       "      <td>-0.267646</td>\n",
       "      <td>-0.272781</td>\n",
       "      <td>0.576960</td>\n",
       "      <td>1.928668</td>\n",
       "      <td>-0.147053</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.022646</td>\n",
       "      <td>-0.240860</td>\n",
       "      <td>1.678331</td>\n",
       "      <td>-0.054762</td>\n",
       "      <td>-0.267306</td>\n",
       "      <td>0.275202</td>\n",
       "      <td>0.312477</td>\n",
       "      <td>-0.072391</td>\n",
       "      <td>0.630330</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47344</th>\n",
       "      <td>1.288996</td>\n",
       "      <td>1.383357</td>\n",
       "      <td>1.713179</td>\n",
       "      <td>0.711904</td>\n",
       "      <td>-0.265775</td>\n",
       "      <td>-0.256330</td>\n",
       "      <td>-0.261520</td>\n",
       "      <td>0.728588</td>\n",
       "      <td>2.330623</td>\n",
       "      <td>1.129475</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.022646</td>\n",
       "      <td>-0.250326</td>\n",
       "      <td>0.400251</td>\n",
       "      <td>-0.238680</td>\n",
       "      <td>-0.346375</td>\n",
       "      <td>1.485493</td>\n",
       "      <td>1.556699</td>\n",
       "      <td>0.470671</td>\n",
       "      <td>0.378581</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47345</th>\n",
       "      <td>-0.672105</td>\n",
       "      <td>-0.457813</td>\n",
       "      <td>-0.577140</td>\n",
       "      <td>-0.443123</td>\n",
       "      <td>-0.277865</td>\n",
       "      <td>-0.268501</td>\n",
       "      <td>-0.273671</td>\n",
       "      <td>0.728588</td>\n",
       "      <td>-0.684039</td>\n",
       "      <td>-0.147053</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.022646</td>\n",
       "      <td>-0.562720</td>\n",
       "      <td>-0.744570</td>\n",
       "      <td>-0.562649</td>\n",
       "      <td>-0.557806</td>\n",
       "      <td>-0.670339</td>\n",
       "      <td>-0.529202</td>\n",
       "      <td>-0.741186</td>\n",
       "      <td>-0.418623</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47346 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       fwd_pkts_tot  bwd_pkts_tot  fwd_data_pkts_tot  bwd_data_pkts_tot  \\\n",
       "0         -0.236304     -0.662387          -0.577140          -0.443123   \n",
       "1         -0.672105     -0.457813          -0.577140          -0.443123   \n",
       "2         -0.454205     -0.662387          -0.577140          -0.443123   \n",
       "3          2.378496      2.406229           2.285759           2.444445   \n",
       "4         -0.672105     -0.457813          -0.577140          -0.443123   \n",
       "...             ...           ...                ...                ...   \n",
       "47341     -0.454205     -0.457813          -0.577140          -0.443123   \n",
       "47342     -0.454205     -0.662387          -0.577140          -0.443123   \n",
       "47343      2.160596      1.997080           2.285759           2.444445   \n",
       "47344      1.288996      1.383357           1.713179           0.711904   \n",
       "47345     -0.672105     -0.457813          -0.577140          -0.443123   \n",
       "\n",
       "       fwd_pkts_per_sec  bwd_pkts_per_sec  flow_pkts_per_sec  down_up_ratio  \\\n",
       "0             -0.277741         -0.268577          -0.273647      -1.394192   \n",
       "1              0.490111          0.504662           0.498222       0.728588   \n",
       "2             -0.277918         -0.268577          -0.273736      -1.394192   \n",
       "3             -0.276874         -0.267504          -0.272675       0.728588   \n",
       "4             -0.277823         -0.268460          -0.273629       0.728588   \n",
       "...                 ...               ...                ...            ...   \n",
       "47341         -0.276776         -0.267991          -0.272869      -0.332802   \n",
       "47342         -0.277509         -0.268577          -0.273530      -1.394192   \n",
       "47343         -0.276943         -0.267646          -0.272781       0.576960   \n",
       "47344         -0.265775         -0.256330          -0.261520       0.728588   \n",
       "47345         -0.277865         -0.268501          -0.273671       0.728588   \n",
       "\n",
       "       fwd_header_size_tot  fwd_header_size_min  ...  flow_pkts_payload.min  \\\n",
       "0                -0.643844            -1.423582  ...              -0.022646   \n",
       "1                -0.643844             0.278456  ...              -0.022646   \n",
       "2                -0.724235            -1.423582  ...              -0.022646   \n",
       "3                 2.129645            -0.147053  ...              -0.022646   \n",
       "4                -0.684039            -0.147053  ...              -0.022646   \n",
       "...                    ...                  ...  ...                    ...   \n",
       "47341            -0.483062            -0.147053  ...              -0.022646   \n",
       "47342            -0.724235            -1.423582  ...              -0.022646   \n",
       "47343             1.928668            -0.147053  ...              -0.022646   \n",
       "47344             2.330623             1.129475  ...              -0.022646   \n",
       "47345            -0.684039            -0.147053  ...              -0.022646   \n",
       "\n",
       "       flow_pkts_payload.max  flow_pkts_payload.tot  flow_pkts_payload.avg  \\\n",
       "0                  -0.562720              -0.744570              -0.562649   \n",
       "1                  -0.562720              -0.744570              -0.562649   \n",
       "2                  -0.562720              -0.744570              -0.562649   \n",
       "3                  -0.240860               1.678331              -0.105550   \n",
       "4                  -0.562720              -0.744570              -0.562649   \n",
       "...                      ...                    ...                    ...   \n",
       "47341              -0.562720              -0.744570              -0.562649   \n",
       "47342              -0.562720              -0.744570              -0.562649   \n",
       "47343              -0.240860               1.678331              -0.054762   \n",
       "47344              -0.250326               0.400251              -0.238680   \n",
       "47345              -0.562720              -0.744570              -0.562649   \n",
       "\n",
       "       flow_pkts_payload.std  fwd_subflow_pkts  bwd_subflow_pkts  \\\n",
       "0                  -0.557806         -0.556874         -0.638986   \n",
       "1                  -0.557806         -0.556874         -0.419418   \n",
       "2                  -0.557806         -0.556874         -0.638986   \n",
       "3                  -0.268638          2.620142          2.654541   \n",
       "4                  -0.557806         -0.670339         -0.529202   \n",
       "...                      ...               ...               ...   \n",
       "47341              -0.557806         -0.329944         -0.419418   \n",
       "47342              -0.557806         -0.556874         -0.638986   \n",
       "47343              -0.267306          0.275202          0.312477   \n",
       "47344              -0.346375          1.485493          1.556699   \n",
       "47345              -0.557806         -0.670339         -0.529202   \n",
       "\n",
       "       fwd_subflow_bytes  bwd_subflow_bytes  is_attack  \n",
       "0              -0.741186          -0.418623        1.0  \n",
       "1              -0.741186          -0.418623        1.0  \n",
       "2              -0.741186          -0.418623        1.0  \n",
       "3               1.265201           2.728235        0.0  \n",
       "4              -0.741186          -0.418623        1.0  \n",
       "...                  ...                ...        ...  \n",
       "47341          -0.741186          -0.418623        1.0  \n",
       "47342          -0.741186          -0.418623        1.0  \n",
       "47343          -0.072391           0.630330        0.0  \n",
       "47344           0.470671           0.378581        0.0  \n",
       "47345          -0.741186          -0.418623        1.0  \n",
       "\n",
       "[47346 rows x 34 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_data = np.column_stack((X, y))\n",
    "\n",
    "features_names = [f\"{feature_names[i]}\" for i in range(X_train_labeled.shape[1])]\n",
    "target_name = \"is_attack\"\n",
    "\n",
    "column_names = features_names + [target_name]\n",
    "\n",
    "combined_df = pd.DataFrame(combined_data, columns=column_names)\n",
    "\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ivoafonsobispo\\anaconda3\\Lib\\site-packages\\lofo\\lofo_importance.py:3: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "from lofo import LOFOImportance, Dataset, plot_importance\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 237, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000185 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 750\n",
      "[LightGBM] [Info] Number of data points in the train set: 354, number of used features: 31\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.669492 -> initscore=0.705886\n",
      "[LightGBM] [Info] Start training from score 0.705886\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 236, number of negative: 119\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000132 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 781\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 31\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.664789 -> initscore=0.684708\n",
      "[LightGBM] [Info] Start training from score 0.684708\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 237, number of negative: 118\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000121 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 756\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 31\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.667606 -> initscore=0.697376\n",
      "[LightGBM] [Info] Start training from score 0.697376\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 238, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000045 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 778\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 31\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.670423 -> initscore=0.710097\n",
      "[LightGBM] [Info] Start training from score 0.710097\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c66336f9a3c7460bb19dc3f4ab7cf596",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 237, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000190 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 732\n",
      "[LightGBM] [Info] Number of data points in the train set: 354, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.669492 -> initscore=0.705886\n",
      "[LightGBM] [Info] Start training from score 0.705886\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 236, number of negative: 119\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000123 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 761\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.664789 -> initscore=0.684708\n",
      "[LightGBM] [Info] Start training from score 0.684708\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 237, number of negative: 118\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000119 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 736\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.667606 -> initscore=0.697376\n",
      "[LightGBM] [Info] Start training from score 0.697376\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 238, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000137 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 759\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.670423 -> initscore=0.710097\n",
      "[LightGBM] [Info] Start training from score 0.710097\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 237, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000179 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 722\n",
      "[LightGBM] [Info] Number of data points in the train set: 354, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.669492 -> initscore=0.705886\n",
      "[LightGBM] [Info] Start training from score 0.705886\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 236, number of negative: 119\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000160 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 750\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.664789 -> initscore=0.684708\n",
      "[LightGBM] [Info] Start training from score 0.684708\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 237, number of negative: 118\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000157 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 730\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.667606 -> initscore=0.697376\n",
      "[LightGBM] [Info] Start training from score 0.697376\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 238, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000124 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 749\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.670423 -> initscore=0.710097\n",
      "[LightGBM] [Info] Start training from score 0.710097\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 237, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000170 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 744\n",
      "[LightGBM] [Info] Number of data points in the train set: 354, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.669492 -> initscore=0.705886\n",
      "[LightGBM] [Info] Start training from score 0.705886\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 236, number of negative: 119\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000150 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 775\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.664789 -> initscore=0.684708\n",
      "[LightGBM] [Info] Start training from score 0.684708\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 237, number of negative: 118\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000093 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 750\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.667606 -> initscore=0.697376\n",
      "[LightGBM] [Info] Start training from score 0.697376\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 238, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000128 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 772\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.670423 -> initscore=0.710097\n",
      "[LightGBM] [Info] Start training from score 0.710097\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 237, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000105 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 745\n",
      "[LightGBM] [Info] Number of data points in the train set: 354, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.669492 -> initscore=0.705886\n",
      "[LightGBM] [Info] Start training from score 0.705886\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 236, number of negative: 119\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000127 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 775\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.664789 -> initscore=0.684708\n",
      "[LightGBM] [Info] Start training from score 0.684708\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 237, number of negative: 118\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000136 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 750\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.667606 -> initscore=0.697376\n",
      "[LightGBM] [Info] Start training from score 0.697376\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 238, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000124 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 772\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.670423 -> initscore=0.710097\n",
      "[LightGBM] [Info] Start training from score 0.710097\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 237, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000156 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 750\n",
      "[LightGBM] [Info] Number of data points in the train set: 354, number of used features: 31\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.669492 -> initscore=0.705886\n",
      "[LightGBM] [Info] Start training from score 0.705886\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 236, number of negative: 119\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000134 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 781\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 31\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.664789 -> initscore=0.684708\n",
      "[LightGBM] [Info] Start training from score 0.684708\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 237, number of negative: 118\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000159 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 756\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 31\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.667606 -> initscore=0.697376\n",
      "[LightGBM] [Info] Start training from score 0.697376\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 238, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000130 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 778\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 31\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.670423 -> initscore=0.710097\n",
      "[LightGBM] [Info] Start training from score 0.710097\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 237, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000163 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 743\n",
      "[LightGBM] [Info] Number of data points in the train set: 354, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.669492 -> initscore=0.705886\n",
      "[LightGBM] [Info] Start training from score 0.705886\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 236, number of negative: 119\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000154 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 775\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.664789 -> initscore=0.684708\n",
      "[LightGBM] [Info] Start training from score 0.684708\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 237, number of negative: 118\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000125 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 749\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.667606 -> initscore=0.697376\n",
      "[LightGBM] [Info] Start training from score 0.697376\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 238, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000130 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 772\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.670423 -> initscore=0.710097\n",
      "[LightGBM] [Info] Start training from score 0.710097\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 237, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000150 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 745\n",
      "[LightGBM] [Info] Number of data points in the train set: 354, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.669492 -> initscore=0.705886\n",
      "[LightGBM] [Info] Start training from score 0.705886\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 236, number of negative: 119\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000124 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 776\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.664789 -> initscore=0.684708\n",
      "[LightGBM] [Info] Start training from score 0.684708\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 237, number of negative: 118\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000145 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 751\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.667606 -> initscore=0.697376\n",
      "[LightGBM] [Info] Start training from score 0.697376\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 238, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000105 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 773\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.670423 -> initscore=0.710097\n",
      "[LightGBM] [Info] Start training from score 0.710097\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 237, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000152 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 729\n",
      "[LightGBM] [Info] Number of data points in the train set: 354, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.669492 -> initscore=0.705886\n",
      "[LightGBM] [Info] Start training from score 0.705886\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 236, number of negative: 119\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000160 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 758\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.664789 -> initscore=0.684708\n",
      "[LightGBM] [Info] Start training from score 0.684708\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 237, number of negative: 118\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000142 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 737\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.667606 -> initscore=0.697376\n",
      "[LightGBM] [Info] Start training from score 0.697376\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 238, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000139 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 758\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.670423 -> initscore=0.710097\n",
      "[LightGBM] [Info] Start training from score 0.710097\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 237, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000133 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 739\n",
      "[LightGBM] [Info] Number of data points in the train set: 354, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.669492 -> initscore=0.705886\n",
      "[LightGBM] [Info] Start training from score 0.705886\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 236, number of negative: 119\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000101 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 769\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.664789 -> initscore=0.684708\n",
      "[LightGBM] [Info] Start training from score 0.684708\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 237, number of negative: 118\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000146 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 745\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.667606 -> initscore=0.697376\n",
      "[LightGBM] [Info] Start training from score 0.697376\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 238, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000127 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 766\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.670423 -> initscore=0.710097\n",
      "[LightGBM] [Info] Start training from score 0.710097\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 237, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000209 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 738\n",
      "[LightGBM] [Info] Number of data points in the train set: 354, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.669492 -> initscore=0.705886\n",
      "[LightGBM] [Info] Start training from score 0.705886\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 236, number of negative: 119\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000131 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 768\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.664789 -> initscore=0.684708\n",
      "[LightGBM] [Info] Start training from score 0.684708\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 237, number of negative: 118\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000138 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 743\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.667606 -> initscore=0.697376\n",
      "[LightGBM] [Info] Start training from score 0.697376\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 238, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000137 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 764\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.670423 -> initscore=0.710097\n",
      "[LightGBM] [Info] Start training from score 0.710097\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 237, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000168 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 735\n",
      "[LightGBM] [Info] Number of data points in the train set: 354, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.669492 -> initscore=0.705886\n",
      "[LightGBM] [Info] Start training from score 0.705886\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 236, number of negative: 119\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000136 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 763\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.664789 -> initscore=0.684708\n",
      "[LightGBM] [Info] Start training from score 0.684708\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 237, number of negative: 118\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000124 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 739\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.667606 -> initscore=0.697376\n",
      "[LightGBM] [Info] Start training from score 0.697376\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 238, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000126 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 761\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.670423 -> initscore=0.710097\n",
      "[LightGBM] [Info] Start training from score 0.710097\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 237, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000162 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 631\n",
      "[LightGBM] [Info] Number of data points in the train set: 354, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.669492 -> initscore=0.705886\n",
      "[LightGBM] [Info] Start training from score 0.705886\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 236, number of negative: 119\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000149 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 662\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.664789 -> initscore=0.684708\n",
      "[LightGBM] [Info] Start training from score 0.684708\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 237, number of negative: 118\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000152 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 637\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.667606 -> initscore=0.697376\n",
      "[LightGBM] [Info] Start training from score 0.697376\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 238, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000119 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 659\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.670423 -> initscore=0.710097\n",
      "[LightGBM] [Info] Start training from score 0.710097\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 237, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000171 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 725\n",
      "[LightGBM] [Info] Number of data points in the train set: 354, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.669492 -> initscore=0.705886\n",
      "[LightGBM] [Info] Start training from score 0.705886\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 236, number of negative: 119\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000115 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 754\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.664789 -> initscore=0.684708\n",
      "[LightGBM] [Info] Start training from score 0.684708\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 237, number of negative: 118\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000042 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 732\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.667606 -> initscore=0.697376\n",
      "[LightGBM] [Info] Start training from score 0.697376\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 238, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000133 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 751\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.670423 -> initscore=0.710097\n",
      "[LightGBM] [Info] Start training from score 0.710097\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 237, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000141 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 743\n",
      "[LightGBM] [Info] Number of data points in the train set: 354, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.669492 -> initscore=0.705886\n",
      "[LightGBM] [Info] Start training from score 0.705886\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 236, number of negative: 119\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000174 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 774\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.664789 -> initscore=0.684708\n",
      "[LightGBM] [Info] Start training from score 0.684708\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 237, number of negative: 118\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000126 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 748\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.667606 -> initscore=0.697376\n",
      "[LightGBM] [Info] Start training from score 0.697376\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 238, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000154 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 770\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.670423 -> initscore=0.710097\n",
      "[LightGBM] [Info] Start training from score 0.710097\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 237, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000134 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 741\n",
      "[LightGBM] [Info] Number of data points in the train set: 354, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.669492 -> initscore=0.705886\n",
      "[LightGBM] [Info] Start training from score 0.705886\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 236, number of negative: 119\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000160 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 771\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.664789 -> initscore=0.684708\n",
      "[LightGBM] [Info] Start training from score 0.684708\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 237, number of negative: 118\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000129 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 747\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.667606 -> initscore=0.697376\n",
      "[LightGBM] [Info] Start training from score 0.697376\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 238, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000133 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 769\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.670423 -> initscore=0.710097\n",
      "[LightGBM] [Info] Start training from score 0.710097\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 237, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000197 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 738\n",
      "[LightGBM] [Info] Number of data points in the train set: 354, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.669492 -> initscore=0.705886\n",
      "[LightGBM] [Info] Start training from score 0.705886\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 236, number of negative: 119\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000106 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 769\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.664789 -> initscore=0.684708\n",
      "[LightGBM] [Info] Start training from score 0.684708\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 237, number of negative: 118\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000111 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 744\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.667606 -> initscore=0.697376\n",
      "[LightGBM] [Info] Start training from score 0.697376\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 238, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000128 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.670423 -> initscore=0.710097\n",
      "[LightGBM] [Info] Start training from score 0.710097\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 237, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000172 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 729\n",
      "[LightGBM] [Info] Number of data points in the train set: 354, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.669492 -> initscore=0.705886\n",
      "[LightGBM] [Info] Start training from score 0.705886\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 236, number of negative: 119\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000130 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 757\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.664789 -> initscore=0.684708\n",
      "[LightGBM] [Info] Start training from score 0.684708\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 237, number of negative: 118\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000126 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 736\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.667606 -> initscore=0.697376\n",
      "[LightGBM] [Info] Start training from score 0.697376\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 238, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000121 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 756\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.670423 -> initscore=0.710097\n",
      "[LightGBM] [Info] Start training from score 0.710097\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 237, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000141 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 727\n",
      "[LightGBM] [Info] Number of data points in the train set: 354, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.669492 -> initscore=0.705886\n",
      "[LightGBM] [Info] Start training from score 0.705886\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 236, number of negative: 119\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000126 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 757\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.664789 -> initscore=0.684708\n",
      "[LightGBM] [Info] Start training from score 0.684708\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 237, number of negative: 118\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000134 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 734\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.667606 -> initscore=0.697376\n",
      "[LightGBM] [Info] Start training from score 0.697376\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 238, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000147 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 752\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.670423 -> initscore=0.710097\n",
      "[LightGBM] [Info] Start training from score 0.710097\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 237, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000142 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 737\n",
      "[LightGBM] [Info] Number of data points in the train set: 354, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.669492 -> initscore=0.705886\n",
      "[LightGBM] [Info] Start training from score 0.705886\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 236, number of negative: 119\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000153 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 767\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.664789 -> initscore=0.684708\n",
      "[LightGBM] [Info] Start training from score 0.684708\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 237, number of negative: 118\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000121 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 741\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.667606 -> initscore=0.697376\n",
      "[LightGBM] [Info] Start training from score 0.697376\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 238, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000169 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 764\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.670423 -> initscore=0.710097\n",
      "[LightGBM] [Info] Start training from score 0.710097\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 237, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000186 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 731\n",
      "[LightGBM] [Info] Number of data points in the train set: 354, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.669492 -> initscore=0.705886\n",
      "[LightGBM] [Info] Start training from score 0.705886\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 236, number of negative: 119\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000165 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 761\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.664789 -> initscore=0.684708\n",
      "[LightGBM] [Info] Start training from score 0.684708\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 237, number of negative: 118\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000131 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 737\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.667606 -> initscore=0.697376\n",
      "[LightGBM] [Info] Start training from score 0.697376\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 238, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000147 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 757\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.670423 -> initscore=0.710097\n",
      "[LightGBM] [Info] Start training from score 0.710097\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 237, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000150 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 631\n",
      "[LightGBM] [Info] Number of data points in the train set: 354, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.669492 -> initscore=0.705886\n",
      "[LightGBM] [Info] Start training from score 0.705886\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 236, number of negative: 119\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000164 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 662\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.664789 -> initscore=0.684708\n",
      "[LightGBM] [Info] Start training from score 0.684708\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 237, number of negative: 118\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000085 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 637\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.667606 -> initscore=0.697376\n",
      "[LightGBM] [Info] Start training from score 0.697376\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 238, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000121 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 659\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.670423 -> initscore=0.710097\n",
      "[LightGBM] [Info] Start training from score 0.710097\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 237, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000259 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 733\n",
      "[LightGBM] [Info] Number of data points in the train set: 354, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.669492 -> initscore=0.705886\n",
      "[LightGBM] [Info] Start training from score 0.705886\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 236, number of negative: 119\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000115 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.664789 -> initscore=0.684708\n",
      "[LightGBM] [Info] Start training from score 0.684708\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 237, number of negative: 118\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000128 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 737\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.667606 -> initscore=0.697376\n",
      "[LightGBM] [Info] Start training from score 0.697376\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 238, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000136 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 759\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.670423 -> initscore=0.710097\n",
      "[LightGBM] [Info] Start training from score 0.710097\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 237, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000307 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 724\n",
      "[LightGBM] [Info] Number of data points in the train set: 354, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.669492 -> initscore=0.705886\n",
      "[LightGBM] [Info] Start training from score 0.705886\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 236, number of negative: 119\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000131 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 752\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.664789 -> initscore=0.684708\n",
      "[LightGBM] [Info] Start training from score 0.684708\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 237, number of negative: 118\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000152 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 729\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.667606 -> initscore=0.697376\n",
      "[LightGBM] [Info] Start training from score 0.697376\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 238, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000122 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 748\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.670423 -> initscore=0.710097\n",
      "[LightGBM] [Info] Start training from score 0.710097\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 237, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000170 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 743\n",
      "[LightGBM] [Info] Number of data points in the train set: 354, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.669492 -> initscore=0.705886\n",
      "[LightGBM] [Info] Start training from score 0.705886\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 236, number of negative: 119\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000118 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 774\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.664789 -> initscore=0.684708\n",
      "[LightGBM] [Info] Start training from score 0.684708\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 237, number of negative: 118\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000120 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 749\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.667606 -> initscore=0.697376\n",
      "[LightGBM] [Info] Start training from score 0.697376\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 238, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000148 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 771\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.670423 -> initscore=0.710097\n",
      "[LightGBM] [Info] Start training from score 0.710097\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 237, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000218 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 730\n",
      "[LightGBM] [Info] Number of data points in the train set: 354, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.669492 -> initscore=0.705886\n",
      "[LightGBM] [Info] Start training from score 0.705886\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 236, number of negative: 119\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000162 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 760\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.664789 -> initscore=0.684708\n",
      "[LightGBM] [Info] Start training from score 0.684708\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 237, number of negative: 118\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000118 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 736\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.667606 -> initscore=0.697376\n",
      "[LightGBM] [Info] Start training from score 0.697376\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 238, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000177 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 756\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.670423 -> initscore=0.710097\n",
      "[LightGBM] [Info] Start training from score 0.710097\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 237, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000145 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 745\n",
      "[LightGBM] [Info] Number of data points in the train set: 354, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.669492 -> initscore=0.705886\n",
      "[LightGBM] [Info] Start training from score 0.705886\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 236, number of negative: 119\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000136 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 776\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.664789 -> initscore=0.684708\n",
      "[LightGBM] [Info] Start training from score 0.684708\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 237, number of negative: 118\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000150 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 751\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.667606 -> initscore=0.697376\n",
      "[LightGBM] [Info] Start training from score 0.697376\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 238, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000129 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 773\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.670423 -> initscore=0.710097\n",
      "[LightGBM] [Info] Start training from score 0.710097\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 237, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000129 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 733\n",
      "[LightGBM] [Info] Number of data points in the train set: 354, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.669492 -> initscore=0.705886\n",
      "[LightGBM] [Info] Start training from score 0.705886\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 236, number of negative: 119\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000172 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.664789 -> initscore=0.684708\n",
      "[LightGBM] [Info] Start training from score 0.684708\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 237, number of negative: 118\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000126 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 740\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.667606 -> initscore=0.697376\n",
      "[LightGBM] [Info] Start training from score 0.697376\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 238, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000140 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 760\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.670423 -> initscore=0.710097\n",
      "[LightGBM] [Info] Start training from score 0.710097\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 237, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000107 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 741\n",
      "[LightGBM] [Info] Number of data points in the train set: 354, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.669492 -> initscore=0.705886\n",
      "[LightGBM] [Info] Start training from score 0.705886\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 236, number of negative: 119\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000159 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 770\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.664789 -> initscore=0.684708\n",
      "[LightGBM] [Info] Start training from score 0.684708\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 237, number of negative: 118\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000153 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 746\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.667606 -> initscore=0.697376\n",
      "[LightGBM] [Info] Start training from score 0.697376\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 238, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000142 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 767\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.670423 -> initscore=0.710097\n",
      "[LightGBM] [Info] Start training from score 0.710097\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 237, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000144 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 631\n",
      "[LightGBM] [Info] Number of data points in the train set: 354, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.669492 -> initscore=0.705886\n",
      "[LightGBM] [Info] Start training from score 0.705886\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 236, number of negative: 119\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000122 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 662\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.664789 -> initscore=0.684708\n",
      "[LightGBM] [Info] Start training from score 0.684708\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 237, number of negative: 118\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000120 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 637\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.667606 -> initscore=0.697376\n",
      "[LightGBM] [Info] Start training from score 0.697376\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 238, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000119 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 659\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.670423 -> initscore=0.710097\n",
      "[LightGBM] [Info] Start training from score 0.710097\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 237, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000150 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 750\n",
      "[LightGBM] [Info] Number of data points in the train set: 354, number of used features: 31\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.669492 -> initscore=0.705886\n",
      "[LightGBM] [Info] Start training from score 0.705886\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 236, number of negative: 119\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000129 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 781\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 31\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.664789 -> initscore=0.684708\n",
      "[LightGBM] [Info] Start training from score 0.684708\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 237, number of negative: 118\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000141 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 756\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 31\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.667606 -> initscore=0.697376\n",
      "[LightGBM] [Info] Start training from score 0.697376\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 238, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000122 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 778\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 31\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.670423 -> initscore=0.710097\n",
      "[LightGBM] [Info] Start training from score 0.710097\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 237, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000176 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 740\n",
      "[LightGBM] [Info] Number of data points in the train set: 354, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.669492 -> initscore=0.705886\n",
      "[LightGBM] [Info] Start training from score 0.705886\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 236, number of negative: 119\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000131 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 771\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.664789 -> initscore=0.684708\n",
      "[LightGBM] [Info] Start training from score 0.684708\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 237, number of negative: 118\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000131 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 746\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.667606 -> initscore=0.697376\n",
      "[LightGBM] [Info] Start training from score 0.697376\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 238, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000125 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 768\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.670423 -> initscore=0.710097\n",
      "[LightGBM] [Info] Start training from score 0.710097\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 237, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000141 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 743\n",
      "[LightGBM] [Info] Number of data points in the train set: 354, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.669492 -> initscore=0.705886\n",
      "[LightGBM] [Info] Start training from score 0.705886\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 236, number of negative: 119\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000135 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 774\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.664789 -> initscore=0.684708\n",
      "[LightGBM] [Info] Start training from score 0.684708\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 237, number of negative: 118\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000115 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 750\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.667606 -> initscore=0.697376\n",
      "[LightGBM] [Info] Start training from score 0.697376\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 238, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000130 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 771\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.670423 -> initscore=0.710097\n",
      "[LightGBM] [Info] Start training from score 0.710097\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 237, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000294 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 732\n",
      "[LightGBM] [Info] Number of data points in the train set: 354, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.669492 -> initscore=0.705886\n",
      "[LightGBM] [Info] Start training from score 0.705886\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 236, number of negative: 119\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000088 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 763\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.664789 -> initscore=0.684708\n",
      "[LightGBM] [Info] Start training from score 0.684708\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 237, number of negative: 118\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000087 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 736\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.667606 -> initscore=0.697376\n",
      "[LightGBM] [Info] Start training from score 0.697376\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 238, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000122 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 760\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.670423 -> initscore=0.710097\n",
      "[LightGBM] [Info] Start training from score 0.710097\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x2000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# extract a sample of the data\n",
    "sample_df = combined_df.sample(frac=0.01, random_state=0)\n",
    "\n",
    "# define the validation scheme\n",
    "cv = KFold(n_splits=4, shuffle=False, random_state=None) # Don't shuffle to keep the time split split validation\n",
    "\n",
    "# define the binary target and the features\n",
    "dataset = Dataset(df=sample_df, target=\"is_attack\", features=[col for col in combined_df.columns if col != \"is_attack\"])\n",
    "\n",
    "# define the validation scheme and scorer. The default model is LightGBM\n",
    "lofo_imp = LOFOImportance(dataset, cv=cv, scoring=\"roc_auc\")\n",
    "\n",
    "# get the mean and standard deviation of the importances in pandas format\n",
    "importance_df = lofo_imp.get_importance()\n",
    "\n",
    "# plot the means and standard deviations of the importances\n",
    "plot_importance(importance_df, figsize=(12, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance_mean</th>\n",
       "      <th>importance_std</th>\n",
       "      <th>val_imp_0</th>\n",
       "      <th>val_imp_1</th>\n",
       "      <th>val_imp_2</th>\n",
       "      <th>val_imp_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>fwd_subflow_pkts</td>\n",
       "      <td>0.003217</td>\n",
       "      <td>0.002064</td>\n",
       "      <td>0.001899</td>\n",
       "      <td>9.868421e-04</td>\n",
       "      <td>0.003570</td>\n",
       "      <td>0.006410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>bwd_pkts_tot</td>\n",
       "      <td>0.001884</td>\n",
       "      <td>0.001143</td>\n",
       "      <td>0.003797</td>\n",
       "      <td>1.315789e-03</td>\n",
       "      <td>0.001623</td>\n",
       "      <td>0.000801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>fwd_pkts_per_sec</td>\n",
       "      <td>0.001785</td>\n",
       "      <td>0.003386</td>\n",
       "      <td>0.004747</td>\n",
       "      <td>1.315789e-03</td>\n",
       "      <td>-0.003570</td>\n",
       "      <td>0.004647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>bwd_header_size_tot</td>\n",
       "      <td>0.001758</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.003165</td>\n",
       "      <td>9.868421e-04</td>\n",
       "      <td>-0.000325</td>\n",
       "      <td>0.003205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>fwd_subflow_bytes</td>\n",
       "      <td>0.001653</td>\n",
       "      <td>0.003871</td>\n",
       "      <td>-0.002532</td>\n",
       "      <td>-9.868421e-04</td>\n",
       "      <td>0.002597</td>\n",
       "      <td>0.007532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>fwd_pkts_payload.std</td>\n",
       "      <td>0.001517</td>\n",
       "      <td>0.001394</td>\n",
       "      <td>0.002848</td>\n",
       "      <td>6.578947e-04</td>\n",
       "      <td>-0.000325</td>\n",
       "      <td>0.002885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>flow_pkts_payload.avg</td>\n",
       "      <td>0.001372</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>0.001266</td>\n",
       "      <td>1.644737e-03</td>\n",
       "      <td>0.000974</td>\n",
       "      <td>0.001603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>flow_pkts_payload.std</td>\n",
       "      <td>0.001240</td>\n",
       "      <td>0.001572</td>\n",
       "      <td>0.001266</td>\n",
       "      <td>6.578947e-04</td>\n",
       "      <td>-0.000649</td>\n",
       "      <td>0.003686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>down_up_ratio</td>\n",
       "      <td>0.001147</td>\n",
       "      <td>0.002441</td>\n",
       "      <td>0.001582</td>\n",
       "      <td>-9.868421e-04</td>\n",
       "      <td>-0.000974</td>\n",
       "      <td>0.004968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fwd_header_size_tot</td>\n",
       "      <td>0.001131</td>\n",
       "      <td>0.000579</td>\n",
       "      <td>0.000316</td>\n",
       "      <td>9.868421e-04</td>\n",
       "      <td>0.001298</td>\n",
       "      <td>0.001923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bwd_pkts_payload.max</td>\n",
       "      <td>0.001127</td>\n",
       "      <td>0.003348</td>\n",
       "      <td>-0.001582</td>\n",
       "      <td>6.578947e-04</td>\n",
       "      <td>-0.001298</td>\n",
       "      <td>0.006731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>bwd_subflow_bytes</td>\n",
       "      <td>0.001043</td>\n",
       "      <td>0.000696</td>\n",
       "      <td>0.000949</td>\n",
       "      <td>-1.110223e-16</td>\n",
       "      <td>0.001298</td>\n",
       "      <td>0.001923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>fwd_pkts_tot</td>\n",
       "      <td>0.000966</td>\n",
       "      <td>0.001978</td>\n",
       "      <td>-0.000316</td>\n",
       "      <td>9.868421e-04</td>\n",
       "      <td>-0.000974</td>\n",
       "      <td>0.004167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>bwd_pkts_payload.avg</td>\n",
       "      <td>0.000964</td>\n",
       "      <td>0.002643</td>\n",
       "      <td>-0.000949</td>\n",
       "      <td>3.289474e-04</td>\n",
       "      <td>-0.000974</td>\n",
       "      <td>0.005449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>bwd_pkts_payload.std</td>\n",
       "      <td>0.000864</td>\n",
       "      <td>0.002023</td>\n",
       "      <td>-0.002532</td>\n",
       "      <td>1.315789e-03</td>\n",
       "      <td>0.001947</td>\n",
       "      <td>0.002724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>flow_pkts_payload.max</td>\n",
       "      <td>0.000483</td>\n",
       "      <td>0.000532</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000649</td>\n",
       "      <td>0.001282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>fwd_pkts_payload.avg</td>\n",
       "      <td>0.000405</td>\n",
       "      <td>0.003167</td>\n",
       "      <td>-0.003165</td>\n",
       "      <td>-9.868421e-04</td>\n",
       "      <td>0.000325</td>\n",
       "      <td>0.005449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bwd_data_pkts_tot</td>\n",
       "      <td>0.000401</td>\n",
       "      <td>0.000694</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>fwd_data_pkts_tot</td>\n",
       "      <td>0.000165</td>\n",
       "      <td>0.000871</td>\n",
       "      <td>-0.000633</td>\n",
       "      <td>-3.289474e-04</td>\n",
       "      <td>0.001623</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bwd_pkts_payload.tot</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>0.000285</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.578947e-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>bwd_subflow_pkts</td>\n",
       "      <td>0.000155</td>\n",
       "      <td>0.001079</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.289474e-04</td>\n",
       "      <td>-0.000974</td>\n",
       "      <td>0.001923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>bwd_pkts_payload.min</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>fwd_header_size_min</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>flow_pkts_payload.min</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>fwd_pkts_payload.max</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>fwd_pkts_payload.min</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>fwd_pkts_payload.tot</td>\n",
       "      <td>-0.000065</td>\n",
       "      <td>0.001165</td>\n",
       "      <td>-0.001899</td>\n",
       "      <td>1.315789e-03</td>\n",
       "      <td>0.000325</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>flow_pkts_payload.tot</td>\n",
       "      <td>-0.000069</td>\n",
       "      <td>0.001586</td>\n",
       "      <td>-0.002532</td>\n",
       "      <td>-3.289474e-04</td>\n",
       "      <td>0.001623</td>\n",
       "      <td>0.000962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>bwd_pkts_per_sec</td>\n",
       "      <td>-0.000071</td>\n",
       "      <td>0.003655</td>\n",
       "      <td>-0.004272</td>\n",
       "      <td>-2.960526e-03</td>\n",
       "      <td>0.004544</td>\n",
       "      <td>0.002404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bwd_header_size_min</td>\n",
       "      <td>-0.000079</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>-0.000316</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>bwd_header_size_max</td>\n",
       "      <td>-0.000245</td>\n",
       "      <td>0.000269</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.289474e-04</td>\n",
       "      <td>-0.000649</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>fwd_header_size_max</td>\n",
       "      <td>-0.000399</td>\n",
       "      <td>0.000518</td>\n",
       "      <td>-0.001266</td>\n",
       "      <td>-3.289474e-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>flow_pkts_per_sec</td>\n",
       "      <td>-0.000528</td>\n",
       "      <td>0.001472</td>\n",
       "      <td>-0.001741</td>\n",
       "      <td>-2.138158e-03</td>\n",
       "      <td>0.000325</td>\n",
       "      <td>0.001442</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  feature  importance_mean  importance_std  val_imp_0  \\\n",
       "32       fwd_subflow_pkts         0.003217        0.002064   0.001899   \n",
       "15           bwd_pkts_tot         0.001884        0.001143   0.003797   \n",
       "20       fwd_pkts_per_sec         0.001785        0.003386   0.004747   \n",
       "21    bwd_header_size_tot         0.001758        0.001500   0.003165   \n",
       "17      fwd_subflow_bytes         0.001653        0.003871  -0.002532   \n",
       "26   fwd_pkts_payload.std         0.001517        0.001394   0.002848   \n",
       "22  flow_pkts_payload.avg         0.001372        0.000273   0.001266   \n",
       "1   flow_pkts_payload.std         0.001240        0.001572   0.001266   \n",
       "18          down_up_ratio         0.001147        0.002441   0.001582   \n",
       "0     fwd_header_size_tot         0.001131        0.000579   0.000316   \n",
       "6    bwd_pkts_payload.max         0.001127        0.003348  -0.001582   \n",
       "30      bwd_subflow_bytes         0.001043        0.000696   0.000949   \n",
       "9            fwd_pkts_tot         0.000966        0.001978  -0.000316   \n",
       "14   bwd_pkts_payload.avg         0.000964        0.002643  -0.000949   \n",
       "27   bwd_pkts_payload.std         0.000864        0.002023  -0.002532   \n",
       "24  flow_pkts_payload.max         0.000483        0.000532   0.000000   \n",
       "12   fwd_pkts_payload.avg         0.000405        0.003167  -0.003165   \n",
       "3       bwd_data_pkts_tot         0.000401        0.000694   0.000000   \n",
       "13      fwd_data_pkts_tot         0.000165        0.000871  -0.000633   \n",
       "2    bwd_pkts_payload.tot         0.000164        0.000285   0.000000   \n",
       "10       bwd_subflow_pkts         0.000155        0.001079   0.000000   \n",
       "29   bwd_pkts_payload.min         0.000000        0.000000   0.000000   \n",
       "25    fwd_header_size_min         0.000000        0.000000   0.000000   \n",
       "4   flow_pkts_payload.min         0.000000        0.000000   0.000000   \n",
       "19   fwd_pkts_payload.max         0.000000        0.000000   0.000000   \n",
       "8    fwd_pkts_payload.min         0.000000        0.000000   0.000000   \n",
       "7    fwd_pkts_payload.tot        -0.000065        0.001165  -0.001899   \n",
       "16  flow_pkts_payload.tot        -0.000069        0.001586  -0.002532   \n",
       "28       bwd_pkts_per_sec        -0.000071        0.003655  -0.004272   \n",
       "5     bwd_header_size_min        -0.000079        0.000137  -0.000316   \n",
       "23    bwd_header_size_max        -0.000245        0.000269   0.000000   \n",
       "31    fwd_header_size_max        -0.000399        0.000518  -0.001266   \n",
       "11      flow_pkts_per_sec        -0.000528        0.001472  -0.001741   \n",
       "\n",
       "       val_imp_1  val_imp_2  val_imp_3  \n",
       "32  9.868421e-04   0.003570   0.006410  \n",
       "15  1.315789e-03   0.001623   0.000801  \n",
       "20  1.315789e-03  -0.003570   0.004647  \n",
       "21  9.868421e-04  -0.000325   0.003205  \n",
       "17 -9.868421e-04   0.002597   0.007532  \n",
       "26  6.578947e-04  -0.000325   0.002885  \n",
       "22  1.644737e-03   0.000974   0.001603  \n",
       "1   6.578947e-04  -0.000649   0.003686  \n",
       "18 -9.868421e-04  -0.000974   0.004968  \n",
       "0   9.868421e-04   0.001298   0.001923  \n",
       "6   6.578947e-04  -0.001298   0.006731  \n",
       "30 -1.110223e-16   0.001298   0.001923  \n",
       "9   9.868421e-04  -0.000974   0.004167  \n",
       "14  3.289474e-04  -0.000974   0.005449  \n",
       "27  1.315789e-03   0.001947   0.002724  \n",
       "24  0.000000e+00   0.000649   0.001282  \n",
       "12 -9.868421e-04   0.000325   0.005449  \n",
       "3   0.000000e+00   0.000000   0.001603  \n",
       "13 -3.289474e-04   0.001623   0.000000  \n",
       "2   6.578947e-04   0.000000   0.000000  \n",
       "10 -3.289474e-04  -0.000974   0.001923  \n",
       "29  0.000000e+00   0.000000   0.000000  \n",
       "25  0.000000e+00   0.000000   0.000000  \n",
       "4   0.000000e+00   0.000000   0.000000  \n",
       "19  0.000000e+00   0.000000   0.000000  \n",
       "8   0.000000e+00   0.000000   0.000000  \n",
       "7   1.315789e-03   0.000325   0.000000  \n",
       "16 -3.289474e-04   0.001623   0.000962  \n",
       "28 -2.960526e-03   0.004544   0.002404  \n",
       "5   0.000000e+00   0.000000   0.000000  \n",
       "23 -3.289474e-04  -0.000649   0.000000  \n",
       "31 -3.289474e-04   0.000000   0.000000  \n",
       "11 -2.138158e-03   0.000325   0.001442  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importance_df"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
