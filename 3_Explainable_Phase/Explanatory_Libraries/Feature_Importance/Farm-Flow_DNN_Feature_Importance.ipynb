{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdd4cc60",
   "metadata": {},
   "source": [
    "# Feature Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f68b9f",
   "metadata": {
    "id": "8_T2LCfAN_XF"
   },
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5dfd5496",
   "metadata": {
    "id": "K1li4zpPN_XH"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjoblib\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c947251b",
   "metadata": {},
   "source": [
    "Load Previous Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1e6a23-3191-4793-8607-0f733b222f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = load_model('../../../2_Modeling_Phase/Binary/Saved-Models/Farm-Flow_DNN-Deep-Neural-Network_Model.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dfca9e7",
   "metadata": {},
   "source": [
    "Load Train Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1401fe5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"../../../0_Datasets/Farm-Flow/train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f658390a",
   "metadata": {},
   "source": [
    "Load Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3cb4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"../../../0_Datasets/Farm-Flow/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fd4fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2ecac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c140ea1",
   "metadata": {},
   "source": [
    "-----\n",
    "## Train and Test Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979449a9",
   "metadata": {},
   "source": [
    "Drop Multiclass Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0413e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.drop('traffic', axis=1)\n",
    "df_test = df_test.drop('traffic', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b524e3",
   "metadata": {},
   "source": [
    "Excluding the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6b5915",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_columns = df_train.columns.drop('is_attack')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5528641e",
   "metadata": {},
   "source": [
    "Create a feature matrix X by selecting only the columns specified in X_columns. Then convert the selected data into a NumPy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd5d3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train[X_columns].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29915f4f",
   "metadata": {},
   "source": [
    "Creates a target variable y containing the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee20a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_train[\"is_attack\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f93c70d",
   "metadata": {},
   "source": [
    "Split into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7e41b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be23d78e",
   "metadata": {},
   "source": [
    "Get Features Names and Class Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e941d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = list(X_columns)\n",
    "class_names = [\"Normal\", \"Malicious\"]\n",
    "response_dict = {0: 'Normal', 1: 'Malicious'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84df84b",
   "metadata": {},
   "source": [
    "Generate Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bdc302",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a40aa2",
   "metadata": {},
   "source": [
    "Labeled Df's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dff7809",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_labeled = pd.DataFrame(X_test, columns=feature_names)\n",
    "X_train_labeled = pd.DataFrame(X_train, columns=feature_names)\n",
    "\n",
    "# Since both are one-dimensional NumPy arrays\n",
    "pred_series = pd.Series(pred.flatten())\n",
    "y_test_target_series = pd.Series(y_test)\n",
    "y_train_target_series = pd.Series(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b6cfc4",
   "metadata": {},
   "source": [
    "Create a subset of the Train DF for faster training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62d929f",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_percentage = 0.1\n",
    "X_subset, _, y_subset, _ = train_test_split(X_train, y_train, test_size=1 - subset_percentage, stratify=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193c31b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_percentage = 0.1\n",
    "X_subset_labeled, _, y_subset_labeled, _ = train_test_split(X_train_labeled, y_train_target_series, test_size=1 - subset_percentage, stratify=y_train_target_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5da0eeb",
   "metadata": {},
   "source": [
    "Row to explain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce198b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2157cbf2",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a1090e-9953-415e-a838-7086fe203cc1",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262c725a-b08f-4763-8827-72024ccb90c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = model.get_weights()\n",
    "\n",
    "# Extract the first layer weights\n",
    "input_layer_weights = weights[0]\n",
    "\n",
    "feature_importance = np.mean(np.abs(input_layer_weights), axis=1)\n",
    "df_feature_importance = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importance})\n",
    "df_feature_importance = df_feature_importance.sort_values(by='Importance', ascending=False).reset_index(drop=True)\n",
    "\n",
    "df_feature_importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d51a619",
   "metadata": {},
   "source": [
    "## Imodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38600ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imodels\n",
    "from imodels import FIGSClassifier\n",
    "\n",
    "#model_figs = FIGSClassifier(max_rules=7, max_trees=3)\n",
    "#model_figs.fit(X_test_labeled, y_test_target_series, feature_names=feature_names)\n",
    "\n",
    "dfp_importance = pd.DataFrame({'feat_names': feature_names})\n",
    "dfp_importance['feature'] = dfp_importance.index\n",
    "dfp_importance_gini = pd.DataFrame({'importance_gini': feature_importance})\n",
    "dfp_importance_gini['feature'] = dfp_importance_gini.index\n",
    "dfp_importance_gini['importance_gini_pct'] = dfp_importance_gini['importance_gini'].rank(pct=True)\n",
    "dfp_importance = pd.merge(dfp_importance, dfp_importance_gini, on='feature', how='left')\n",
    "dfp_importance = dfp_importance.sort_values(by=['importance_gini', 'feature'], ascending=[False, True]).reset_index(drop=True)\n",
    "display(dfp_importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5063e9c-3822-470f-bdce-292f56219fd3",
   "metadata": {},
   "source": [
    "## Shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b9728f-e0e1-4c2c-97cf-ecfb64aa5761",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "masker = shap.maskers.Independent(X_subset)\n",
    "\n",
    "explainer = shap.Explainer(model, masker=masker)\n",
    "#explainer = shap.KernelExplainer(model, data=X_subset)\n",
    "#explainer = shap.TreeExplainer(model)\n",
    "\n",
    "shap_values = explainer.shap_values(X_test_labeled)\n",
    "\n",
    "shap.summary_plot(shap_values, X_test_labeled,feature_names=feature_names,class_names=class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef34933e-f57e-4e46-a130-e107a8becd34",
   "metadata": {},
   "source": [
    "## Shapash"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0788da6f-6f84-405b-8bc7-7d8b630013d6",
   "metadata": {},
   "source": [
    "from shapash import SmartExplainer\n",
    "\n",
    "pred_series_shapash = pred_series.iloc[:len(X_test_labeled)]\n",
    "#pred_series_shapash.index = X_test_subset_labeled.index\n",
    "\n",
    "xpl = SmartExplainer(model=model)\n",
    "xpl.compile(x=X_test_labeled,\n",
    "            y_pred=pred_series,\n",
    "            y_target=y_test_target_series)\n",
    "\n",
    "xpl.plot.features_importance()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bd41f6c5-7c22-456e-9b47-7fb888f45af2",
   "metadata": {},
   "source": [
    "app = xpl.run_app(title_story='Farm-Flow', port=8020)\n",
    "#app.kill()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67e0e1c-c8de-4bd1-9b53-2f7674597285",
   "metadata": {},
   "source": [
    "## InterpretML"
   ]
  },
  {
   "cell_type": "raw",
   "id": "405c1004-f944-4360-a399-1b4c3f39296d",
   "metadata": {},
   "source": [
    "print(model.input_shape)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "09b6fd44-45ff-45da-85c7-2c2894590823",
   "metadata": {},
   "source": [
    "from interpret.blackbox import MorrisSensitivity\n",
    "from sklearn.pipeline import Pipeline\n",
    "from interpret import show\n",
    "from keras.models import Model\n",
    "\n",
    "functional_model = Model(inputs=model.input, outputs=model.output)\n",
    "\n",
    "def predict_fn(X_test_labeled):\n",
    "    return model.predict(X_test_labeled)\n",
    "\n",
    "msa = MorrisSensitivity(predict_fn, X_test_labeled, feature_names=feature_names)\n",
    "\n",
    "show(msa.explain_global())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396f22da",
   "metadata": {},
   "source": [
    "## LOFO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc93864f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lofo import LOFOImportance, Dataset, plot_importance\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "target_name = \"is_attack\"\n",
    "\n",
    "column_names = feature_names + [target_name]\n",
    "\n",
    "combined_data = np.column_stack((X_test_labeled, y_test_target_series))\n",
    "combined_df = pd.DataFrame(combined_data, columns=column_names)\n",
    "\n",
    "# define the validation scheme\n",
    "cv = KFold(n_splits=4, shuffle=False, random_state=None) # Don't shuffle to keep the time split split validation\n",
    "\n",
    "# define the binary target and the features\n",
    "dataset = Dataset(df=combined_df, target=\"is_attack\", features=[col for col in combined_df.columns if col != \"is_attack\"])\n",
    "\n",
    "# define the validation scheme and scorer. The default model is LightGBM\n",
    "lofo_imp = LOFOImportance(dataset, cv=cv, scoring=\"roc_auc\")\n",
    "\n",
    "# get the mean and standard deviation of the importances in pandas format\n",
    "importance = lofo_imp.get_importance()\n",
    "\n",
    "importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd946c5f",
   "metadata": {},
   "source": [
    "------\n",
    "## Notes\n",
    "\n",
    "**SHAP Values vs Permutation Importance vs Morris Sensitivity vs LOFO (Leave One Feature Out)**\n",
    "\n",
    "1. **SHAP Values:**\n",
    "- **Concept:** SHAP values are based on cooperative game theory and aim to fairly distribute the contribution of each feature to the model's prediction.\n",
    "- **How it works:** It calculates the average contribution of each feature across all possible feature combinations and assigns a value to each feature, indicating its impact on the prediction.\n",
    "- **Interpretation:** A positive SHAP value for a feature contributes to increasing the model's output, while a negative value indicates a contribution to decreasing the output.\n",
    "\n",
    "2. **Permutation Importance:**\n",
    "- **Concept:** Permutation Importance assesses the importance of each feature by permuting (randomly shuffling) its values and observing the change in the model's performance.\n",
    "- **How it works:** It measures the decrease in model performance (e.g., accuracy) when the values of a specific feature are randomly permuted, and the larger the decrease, the more important the feature is considered.\n",
    "- **Interpretation:** A higher decrease in performance suggests that the feature is crucial for the model's predictions.\n",
    "\n",
    "3. **Morris Sensitivity:**\n",
    "- **Concept:** Morris Sensitivity is a global sensitivity analysis method that assesses the impact of small variations in individual features on the model's output.\n",
    "- **How it works:** It involves perturbing one feature at a time while keeping other features constant, observing how the output changes, and quantifying the sensitivity of the model to each feature.\n",
    "- **Interpretation:** A higher Morris Sensitivity value indicates a greater impact of the feature on the model output.\n",
    "\n",
    "4. **LOFO (Leave One Feature Out):**\n",
    "- **Concept:** LOFO evaluates the impact of leaving out each feature one at a time on the model's performance.\n",
    "- **How it works:** It systematically removes each feature, re-trains the model, and measures the change in performance metrics (e.g., accuracy, AUC) to understand the importance of each feature.\n",
    "- **Interpretation:** A larger decrease in performance when a specific feature is left out suggests that the feature is more critical for the model's predictions.\n",
    "\n",
    "**Assumptions:**\n",
    "- **SHAP Values:** Assumes that features interact cooperatively.\n",
    "- **Permutation Importance:** Assumes that the change in model performance is solely due to the importance of the feature.\n",
    "- **Morris Sensitivity:** Assumes small variations in individual features.\n",
    "- **LOFO:** Assumes that leaving out a feature impacts the model's performance.\n",
    "\n",
    "### Q: Why are the results from the XGBoost Feature Importance different from the results of the DNN?\n",
    "XGBoost relies on decision trees, where each feature's importance is determined by its contribution to the reduction in impurity (Gini) in the decision tree nodes. Results in a clear and interpretable feature importance. On the other hand, DNNs are non-linear models, making them harder to interpret.\n",
    "\n",
    "**In cybersecurity:**\n",
    "\n",
    "The text discusses the number of packets with payload as a common feature, and asserts that the results vary based on the type of Feature Importance algorithm used.\n",
    "\n",
    "- **Permutation Importance:** identifies the time between each package sent as having the most influence.\n",
    "- **Shap:** identifies backward communication starting with subflow or packet size as having the most influence.\n",
    "- **Morris Sensitivity:** the minimum payload size has been identified as having the most influence, which is reasonable given that it is an IoT dataset and consistency in the minimum payload size is crucial.\n",
    "- **LOFO:** despite being mentioned after several other features, another proposition suggests that the payload size, including the packet header size, has more influence.\n",
    "\n",
    "Understanding each feature with XGBoost is possible, but it becomes challenging with NN due to the varying results obtained from different techniques. Nevertheless, the packet consistently yields the same result across all techniques.\n",
    "\n",
    "This highlights the importance of considering the interpretability of models, especially when dealing with complex neural networks, and understanding that different interpretability techniques may yield divergent results. The consistency in the interpretation of the \"packet\" feature across various techniques adds confidence to its significance in the context of the cybersecurity dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d747b9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
