{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdd4cc60",
   "metadata": {},
   "source": [
    "# Feature Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f68b9f",
   "metadata": {
    "id": "8_T2LCfAN_XF"
   },
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5dfd5496",
   "metadata": {
    "id": "K1li4zpPN_XH"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c947251b",
   "metadata": {},
   "source": [
    "Load Previous Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb1e6a23-3191-4793-8607-0f733b222f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-14 13:48:17.334807: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-14 13:48:17.364290: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-14 13:48:17.364320: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-14 13:48:17.364981: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-14 13:48:17.369432: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-14 13:48:18.009856: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] Unable to synchronously open file (unable to open file: name = '../2_Modeling_Phase/Saved-Models/Farm-Flow_DNN-Deep-Neural-Network_Model.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_model\n\u001b[0;32m----> 3\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../2_Modeling_Phase/Saved-Models/Farm-Flow_DNN-Deep-Neural-Network_Model.h5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/saving/saving_api.py:183\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m saving_lib\u001b[38;5;241m.\u001b[39mload_model(\n\u001b[1;32m    177\u001b[0m         filepath,\n\u001b[1;32m    178\u001b[0m         custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects,\n\u001b[1;32m    179\u001b[0m         \u001b[38;5;28mcompile\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcompile\u001b[39m,\n\u001b[1;32m    180\u001b[0m         safe_mode\u001b[38;5;241m=\u001b[39msafe_mode,\n\u001b[1;32m    181\u001b[0m     )\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath)\u001b[38;5;241m.\u001b[39mendswith((\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.hdf5\u001b[39m\u001b[38;5;124m\"\u001b[39m)):\n\u001b[0;32m--> 183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlegacy_h5_format\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model_from_hdf5\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath)\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.keras\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    186\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile not found: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    187\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease ensure the file is an accessible `.keras` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    188\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzip file.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    189\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/legacy/saving/legacy_h5_format.py:116\u001b[0m, in \u001b[0;36mload_model_from_hdf5\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    114\u001b[0m opened_new_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(filepath, h5py\u001b[38;5;241m.\u001b[39mFile)\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m opened_new_file:\n\u001b[0;32m--> 116\u001b[0m     f \u001b[38;5;241m=\u001b[39m \u001b[43mh5py\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    118\u001b[0m     f \u001b[38;5;241m=\u001b[39m filepath\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/h5py/_hl/files.py:562\u001b[0m, in \u001b[0;36mFile.__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[1;32m    553\u001b[0m     fapl \u001b[38;5;241m=\u001b[39m make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,\n\u001b[1;32m    554\u001b[0m                      locking, page_buf_size, min_meta_keep, min_raw_keep,\n\u001b[1;32m    555\u001b[0m                      alignment_threshold\u001b[38;5;241m=\u001b[39malignment_threshold,\n\u001b[1;32m    556\u001b[0m                      alignment_interval\u001b[38;5;241m=\u001b[39malignment_interval,\n\u001b[1;32m    557\u001b[0m                      meta_block_size\u001b[38;5;241m=\u001b[39mmeta_block_size,\n\u001b[1;32m    558\u001b[0m                      \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    559\u001b[0m     fcpl \u001b[38;5;241m=\u001b[39m make_fcpl(track_order\u001b[38;5;241m=\u001b[39mtrack_order, fs_strategy\u001b[38;5;241m=\u001b[39mfs_strategy,\n\u001b[1;32m    560\u001b[0m                      fs_persist\u001b[38;5;241m=\u001b[39mfs_persist, fs_threshold\u001b[38;5;241m=\u001b[39mfs_threshold,\n\u001b[1;32m    561\u001b[0m                      fs_page_size\u001b[38;5;241m=\u001b[39mfs_page_size)\n\u001b[0;32m--> 562\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mmake_fid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muserblock_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfcpl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mswmr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mswmr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    564\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(libver, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    565\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_libver \u001b[38;5;241m=\u001b[39m libver\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/h5py/_hl/files.py:235\u001b[0m, in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m swmr \u001b[38;5;129;01mand\u001b[39;00m swmr_support:\n\u001b[1;32m    234\u001b[0m         flags \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mACC_SWMR_READ\n\u001b[0;32m--> 235\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mh5f\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfapl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    237\u001b[0m     fid \u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mopen(name, h5f\u001b[38;5;241m.\u001b[39mACC_RDWR, fapl\u001b[38;5;241m=\u001b[39mfapl)\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/h5f.pyx:102\u001b[0m, in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] Unable to synchronously open file (unable to open file: name = '../2_Modeling_Phase/Saved-Models/Farm-Flow_DNN-Deep-Neural-Network_Model.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = load_model('../2_Modeling_Phase/Saved-Models/Farm-Flow_DNN-Deep-Neural-Network_Model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dfca9e7",
   "metadata": {},
   "source": [
    "Load Train Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1401fe5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"../0_Datasets/Farm-Flow/train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f658390a",
   "metadata": {},
   "source": [
    "Load Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3cb4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"../0_Datasets/Farm-Flow/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fd4fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2ecac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c140ea1",
   "metadata": {},
   "source": [
    "-----\n",
    "## Train and Test Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979449a9",
   "metadata": {},
   "source": [
    "Drop Multiclass Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0413e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.drop('traffic', axis=1)\n",
    "df_test = df_test.drop('traffic', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b524e3",
   "metadata": {},
   "source": [
    "Excluding the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6b5915",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_columns = df_train.columns.drop('is_attack')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5528641e",
   "metadata": {},
   "source": [
    "Create a feature matrix X by selecting only the columns specified in X_columns. Then convert the selected data into a NumPy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd5d3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train[X_columns].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29915f4f",
   "metadata": {},
   "source": [
    "Creates a target variable y containing the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee20a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_train[\"is_attack\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f93c70d",
   "metadata": {},
   "source": [
    "Split into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7e41b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be23d78e",
   "metadata": {},
   "source": [
    "Get Features Names and Class Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e941d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = list(X_columns)\n",
    "class_names = [\"Normal\", \"Malicious\"]\n",
    "response_dict = {0: 'Normal', 1: 'Malicious'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84df84b",
   "metadata": {},
   "source": [
    "Generate Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bdc302",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a40aa2",
   "metadata": {},
   "source": [
    "Labeled Df's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dff7809",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_labeled = pd.DataFrame(X_test, columns=feature_names)\n",
    "X_train_labeled = pd.DataFrame(X_train, columns=feature_names)\n",
    "\n",
    "# Since both are one-dimensional NumPy arrays\n",
    "pred_series = pd.Series(pred.flatten())\n",
    "y_test_target_series = pd.Series(y_test)\n",
    "y_train_target_series = pd.Series(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b6cfc4",
   "metadata": {},
   "source": [
    "Create a subset of the Train DF for faster training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62d929f",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_percentage = 0.1\n",
    "X_subset, _, y_subset, _ = train_test_split(X_train, y_train, test_size=1 - subset_percentage, stratify=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193c31b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_percentage = 0.1\n",
    "X_subset_labeled, _, y_subset_labeled, _ = train_test_split(X_train_labeled, y_train_target_series, test_size=1 - subset_percentage, stratify=y_train_target_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5da0eeb",
   "metadata": {},
   "source": [
    "Row to explain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce198b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2157cbf2",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a1090e-9953-415e-a838-7086fe203cc1",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262c725a-b08f-4763-8827-72024ccb90c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = model.get_weights()\n",
    "\n",
    "# Extract the first layer weights\n",
    "input_layer_weights = weights[0]\n",
    "\n",
    "feature_importance = np.mean(np.abs(input_layer_weights), axis=1)\n",
    "df_feature_importance = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importance})\n",
    "df_feature_importance = df_feature_importance.sort_values(by='Importance', ascending=False).reset_index(drop=True)\n",
    "\n",
    "df_feature_importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d51a619",
   "metadata": {},
   "source": [
    "## Imodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38600ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imodels\n",
    "from imodels import FIGSClassifier\n",
    "\n",
    "#model_figs = FIGSClassifier(max_rules=7, max_trees=3)\n",
    "#model_figs.fit(X_test_labeled, y_test_target_series, feature_names=feature_names)\n",
    "\n",
    "dfp_importance = pd.DataFrame({'feat_names': feature_names})\n",
    "dfp_importance['feature'] = dfp_importance.index\n",
    "dfp_importance_gini = pd.DataFrame({'importance_gini': feature_importance})\n",
    "dfp_importance_gini['feature'] = dfp_importance_gini.index\n",
    "dfp_importance_gini['importance_gini_pct'] = dfp_importance_gini['importance_gini'].rank(pct=True)\n",
    "dfp_importance = pd.merge(dfp_importance, dfp_importance_gini, on='feature', how='left')\n",
    "dfp_importance = dfp_importance.sort_values(by=['importance_gini', 'feature'], ascending=[False, True]).reset_index(drop=True)\n",
    "display(dfp_importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5063e9c-3822-470f-bdce-292f56219fd3",
   "metadata": {},
   "source": [
    "## Shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b9728f-e0e1-4c2c-97cf-ecfb64aa5761",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "masker = shap.maskers.Independent(X_subset)\n",
    "\n",
    "explainer = shap.Explainer(model, masker=masker)\n",
    "#explainer = shap.KernelExplainer(model, data=X_subset)\n",
    "#explainer = shap.TreeExplainer(model)\n",
    "\n",
    "shap_values = explainer.shap_values(X_test_labeled)\n",
    "\n",
    "shap.summary_plot(shap_values, X_test_labeled,feature_names=feature_names,class_names=class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef34933e-f57e-4e46-a130-e107a8becd34",
   "metadata": {},
   "source": [
    "## Shapash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ce3c27-9fad-4b8d-9eb6-e38d48cc1d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapash import SmartExplainer\n",
    "\n",
    "pred_series_shapash = pred_series.iloc[:len(X_test_labeled)]\n",
    "#pred_series_shapash.index = X_test_subset_labeled.index\n",
    "\n",
    "xpl = SmartExplainer(model=model)\n",
    "xpl.compile(x=X_test_labeled,\n",
    "            y_pred=pred_series,\n",
    "            y_target=y_test_target_series)\n",
    "\n",
    "xpl.plot.features_importance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6093a5-d98d-4eae-9036-f0e31037db01",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = xpl.run_app(title_story='Farm-Flow', port=8020)\n",
    "#app.kill()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67e0e1c-c8de-4bd1-9b53-2f7674597285",
   "metadata": {},
   "source": [
    "## InterpretML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80045c5-5e9c-400f-ba91-283bec11ecca",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6cc1bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from interpret.blackbox import MorrisSensitivity\n",
    "from sklearn.pipeline import Pipeline\n",
    "from interpret import show\n",
    "from keras.models import Model\n",
    "\n",
    "functional_model = Model(inputs=model.input, outputs=model.output)\n",
    "\n",
    "def predict_fn(X_test_labeled):\n",
    "    return model.predict(X_test_labeled)\n",
    "\n",
    "msa = MorrisSensitivity(predict_fn, X_test_labeled, feature_names=feature_names)\n",
    "\n",
    "show(msa.explain_global())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396f22da",
   "metadata": {},
   "source": [
    "## LOFO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc93864f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lofo import LOFOImportance, Dataset, plot_importance\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "target_name = \"is_attack\"\n",
    "\n",
    "column_names = feature_names + [target_name]\n",
    "\n",
    "combined_data = np.column_stack((X_test_labeled, y_test_target_series))\n",
    "combined_df = pd.DataFrame(combined_data, columns=column_names)\n",
    "\n",
    "# define the validation scheme\n",
    "cv = KFold(n_splits=4, shuffle=False, random_state=None) # Don't shuffle to keep the time split split validation\n",
    "\n",
    "# define the binary target and the features\n",
    "dataset = Dataset(df=combined_df, target=\"is_attack\", features=[col for col in combined_df.columns if col != \"is_attack\"])\n",
    "\n",
    "# define the validation scheme and scorer. The default model is LightGBM\n",
    "lofo_imp = LOFOImportance(dataset, cv=cv, scoring=\"roc_auc\")\n",
    "\n",
    "# get the mean and standard deviation of the importances in pandas format\n",
    "importance = lofo_imp.get_importance()\n",
    "\n",
    "importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd946c5f",
   "metadata": {},
   "source": [
    "------\n",
    "## Notes\n",
    "\n",
    "**SHAP Values vs Permutation Importance vs Morris Sensitivity vs LOFO (Leave One Feature Out)**\n",
    "\n",
    "1. **SHAP Values:**\n",
    "- **Concept:** SHAP values are based on cooperative game theory and aim to fairly distribute the contribution of each feature to the model's prediction.\n",
    "- **How it works:** It calculates the average contribution of each feature across all possible feature combinations and assigns a value to each feature, indicating its impact on the prediction.\n",
    "- **Interpretation:** A positive SHAP value for a feature contributes to increasing the model's output, while a negative value indicates a contribution to decreasing the output.\n",
    "\n",
    "2. **Permutation Importance:**\n",
    "- **Concept:** Permutation Importance assesses the importance of each feature by permuting (randomly shuffling) its values and observing the change in the model's performance.\n",
    "- **How it works:** It measures the decrease in model performance (e.g., accuracy) when the values of a specific feature are randomly permuted, and the larger the decrease, the more important the feature is considered.\n",
    "- **Interpretation:** A higher decrease in performance suggests that the feature is crucial for the model's predictions.\n",
    "\n",
    "3. **Morris Sensitivity:**\n",
    "- **Concept:** Morris Sensitivity is a global sensitivity analysis method that assesses the impact of small variations in individual features on the model's output.\n",
    "- **How it works:** It involves perturbing one feature at a time while keeping other features constant, observing how the output changes, and quantifying the sensitivity of the model to each feature.\n",
    "- **Interpretation:** A higher Morris Sensitivity value indicates a greater impact of the feature on the model output.\n",
    "\n",
    "4. **LOFO (Leave One Feature Out):**\n",
    "- **Concept:** LOFO evaluates the impact of leaving out each feature one at a time on the model's performance.\n",
    "- **How it works:** It systematically removes each feature, re-trains the model, and measures the change in performance metrics (e.g., accuracy, AUC) to understand the importance of each feature.\n",
    "- **Interpretation:** A larger decrease in performance when a specific feature is left out suggests that the feature is more critical for the model's predictions.\n",
    "\n",
    "**Assumptions:**\n",
    "- **SHAP Values:** Assumes that features interact cooperatively.\n",
    "- **Permutation Importance:** Assumes that the change in model performance is solely due to the importance of the feature.\n",
    "- **Morris Sensitivity:** Assumes small variations in individual features.\n",
    "- **LOFO:** Assumes that leaving out a feature impacts the model's performance.\n",
    "\n",
    "### Q: Why are the results from the XGBoost Feature Importance different from the results of the DNN?\n",
    "XGBoost relies on decision trees, where each feature's importance is determined by its contribution to the reduction in impurity (Gini) in the decision tree nodes. Results in a clear and interpretable feature importance. On the other hand, DNNs are non-linear models, making them harder to interpret.\n",
    "\n",
    "**In cybersecurity:**\n",
    "\n",
    "The text discusses the number of packets with payload as a common feature, and asserts that the results vary based on the type of Feature Importance algorithm used.\n",
    "\n",
    "- **Permutation Importance:** identifies the time between each package sent as having the most influence.\n",
    "- **Shap:** identifies backward communication starting with subflow or packet size as having the most influence.\n",
    "- **Morris Sensitivity:** the minimum payload size has been identified as having the most influence, which is reasonable given that it is an IoT dataset and consistency in the minimum payload size is crucial.\n",
    "- **LOFO:** despite being mentioned after several other features, another proposition suggests that the payload size, including the packet header size, has more influence.\n",
    "\n",
    "Understanding each feature with XGBoost is possible, but it becomes challenging with NN due to the varying results obtained from different techniques. Nevertheless, the packet consistently yields the same result across all techniques.\n",
    "\n",
    "This highlights the importance of considering the interpretability of models, especially when dealing with complex neural networks, and understanding that different interpretability techniques may yield divergent results. The consistency in the interpretation of the \"packet\" feature across various techniques adds confidence to its significance in the context of the cybersecurity dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d747b9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
