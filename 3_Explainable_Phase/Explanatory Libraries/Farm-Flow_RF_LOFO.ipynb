{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Model + Explainable AI Techniques (XAI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8_T2LCfAN_XF"
   },
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "K1li4zpPN_XH"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Train Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"../../0_Datasets/Farm-Flow/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fwd_pkts_tot</th>\n",
       "      <th>bwd_pkts_tot</th>\n",
       "      <th>fwd_data_pkts_tot</th>\n",
       "      <th>bwd_data_pkts_tot</th>\n",
       "      <th>fwd_pkts_per_sec</th>\n",
       "      <th>bwd_pkts_per_sec</th>\n",
       "      <th>flow_pkts_per_sec</th>\n",
       "      <th>down_up_ratio</th>\n",
       "      <th>fwd_header_size_tot</th>\n",
       "      <th>fwd_header_size_min</th>\n",
       "      <th>...</th>\n",
       "      <th>flow_pkts_payload.max</th>\n",
       "      <th>flow_pkts_payload.tot</th>\n",
       "      <th>flow_pkts_payload.avg</th>\n",
       "      <th>flow_pkts_payload.std</th>\n",
       "      <th>fwd_subflow_pkts</th>\n",
       "      <th>bwd_subflow_pkts</th>\n",
       "      <th>fwd_subflow_bytes</th>\n",
       "      <th>bwd_subflow_bytes</th>\n",
       "      <th>traffic</th>\n",
       "      <th>is_attack</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.236304</td>\n",
       "      <td>-0.662387</td>\n",
       "      <td>-0.577140</td>\n",
       "      <td>-0.443123</td>\n",
       "      <td>-0.277741</td>\n",
       "      <td>-0.268577</td>\n",
       "      <td>-0.273647</td>\n",
       "      <td>-1.394192</td>\n",
       "      <td>-0.643844</td>\n",
       "      <td>-1.423582</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.562720</td>\n",
       "      <td>-0.744570</td>\n",
       "      <td>-0.562649</td>\n",
       "      <td>-0.557806</td>\n",
       "      <td>-0.556874</td>\n",
       "      <td>-0.638986</td>\n",
       "      <td>-0.741186</td>\n",
       "      <td>-0.418623</td>\n",
       "      <td>UDP_Flood</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.672105</td>\n",
       "      <td>-0.457813</td>\n",
       "      <td>-0.577140</td>\n",
       "      <td>-0.443123</td>\n",
       "      <td>0.490111</td>\n",
       "      <td>0.504662</td>\n",
       "      <td>0.498222</td>\n",
       "      <td>0.728588</td>\n",
       "      <td>-0.643844</td>\n",
       "      <td>0.278456</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.562720</td>\n",
       "      <td>-0.744570</td>\n",
       "      <td>-0.562649</td>\n",
       "      <td>-0.557806</td>\n",
       "      <td>-0.556874</td>\n",
       "      <td>-0.419418</td>\n",
       "      <td>-0.741186</td>\n",
       "      <td>-0.418623</td>\n",
       "      <td>Port_Scanning</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.454205</td>\n",
       "      <td>-0.662387</td>\n",
       "      <td>-0.577140</td>\n",
       "      <td>-0.443123</td>\n",
       "      <td>-0.277918</td>\n",
       "      <td>-0.268577</td>\n",
       "      <td>-0.273736</td>\n",
       "      <td>-1.394192</td>\n",
       "      <td>-0.724235</td>\n",
       "      <td>-1.423582</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.562720</td>\n",
       "      <td>-0.744570</td>\n",
       "      <td>-0.562649</td>\n",
       "      <td>-0.557806</td>\n",
       "      <td>-0.556874</td>\n",
       "      <td>-0.638986</td>\n",
       "      <td>-0.741186</td>\n",
       "      <td>-0.418623</td>\n",
       "      <td>UDP_Flood</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.378496</td>\n",
       "      <td>2.406229</td>\n",
       "      <td>2.285759</td>\n",
       "      <td>2.444445</td>\n",
       "      <td>-0.276874</td>\n",
       "      <td>-0.267504</td>\n",
       "      <td>-0.272675</td>\n",
       "      <td>0.728588</td>\n",
       "      <td>2.129645</td>\n",
       "      <td>-0.147053</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.240860</td>\n",
       "      <td>1.678331</td>\n",
       "      <td>-0.105550</td>\n",
       "      <td>-0.268638</td>\n",
       "      <td>2.620142</td>\n",
       "      <td>2.654541</td>\n",
       "      <td>1.265201</td>\n",
       "      <td>2.728235</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.672105</td>\n",
       "      <td>-0.457813</td>\n",
       "      <td>-0.577140</td>\n",
       "      <td>-0.443123</td>\n",
       "      <td>-0.277823</td>\n",
       "      <td>-0.268460</td>\n",
       "      <td>-0.273629</td>\n",
       "      <td>0.728588</td>\n",
       "      <td>-0.684039</td>\n",
       "      <td>-0.147053</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.562720</td>\n",
       "      <td>-0.744570</td>\n",
       "      <td>-0.562649</td>\n",
       "      <td>-0.557806</td>\n",
       "      <td>-0.670339</td>\n",
       "      <td>-0.529202</td>\n",
       "      <td>-0.741186</td>\n",
       "      <td>-0.418623</td>\n",
       "      <td>MQTT_Flood</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47341</th>\n",
       "      <td>-0.454205</td>\n",
       "      <td>-0.457813</td>\n",
       "      <td>-0.577140</td>\n",
       "      <td>-0.443123</td>\n",
       "      <td>-0.276776</td>\n",
       "      <td>-0.267991</td>\n",
       "      <td>-0.272869</td>\n",
       "      <td>-0.332802</td>\n",
       "      <td>-0.483062</td>\n",
       "      <td>-0.147053</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.562720</td>\n",
       "      <td>-0.744570</td>\n",
       "      <td>-0.562649</td>\n",
       "      <td>-0.557806</td>\n",
       "      <td>-0.329944</td>\n",
       "      <td>-0.419418</td>\n",
       "      <td>-0.741186</td>\n",
       "      <td>-0.418623</td>\n",
       "      <td>TCP_Flood</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47342</th>\n",
       "      <td>-0.454205</td>\n",
       "      <td>-0.662387</td>\n",
       "      <td>-0.577140</td>\n",
       "      <td>-0.443123</td>\n",
       "      <td>-0.277509</td>\n",
       "      <td>-0.268577</td>\n",
       "      <td>-0.273530</td>\n",
       "      <td>-1.394192</td>\n",
       "      <td>-0.724235</td>\n",
       "      <td>-1.423582</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.562720</td>\n",
       "      <td>-0.744570</td>\n",
       "      <td>-0.562649</td>\n",
       "      <td>-0.557806</td>\n",
       "      <td>-0.556874</td>\n",
       "      <td>-0.638986</td>\n",
       "      <td>-0.741186</td>\n",
       "      <td>-0.418623</td>\n",
       "      <td>UDP_Flood</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47343</th>\n",
       "      <td>2.160596</td>\n",
       "      <td>1.997080</td>\n",
       "      <td>2.285759</td>\n",
       "      <td>2.444445</td>\n",
       "      <td>-0.276943</td>\n",
       "      <td>-0.267646</td>\n",
       "      <td>-0.272781</td>\n",
       "      <td>0.576960</td>\n",
       "      <td>1.928668</td>\n",
       "      <td>-0.147053</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.240860</td>\n",
       "      <td>1.678331</td>\n",
       "      <td>-0.054762</td>\n",
       "      <td>-0.267306</td>\n",
       "      <td>0.275202</td>\n",
       "      <td>0.312477</td>\n",
       "      <td>-0.072391</td>\n",
       "      <td>0.630330</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47344</th>\n",
       "      <td>1.288996</td>\n",
       "      <td>1.383357</td>\n",
       "      <td>1.713179</td>\n",
       "      <td>0.711904</td>\n",
       "      <td>-0.265775</td>\n",
       "      <td>-0.256330</td>\n",
       "      <td>-0.261520</td>\n",
       "      <td>0.728588</td>\n",
       "      <td>2.330623</td>\n",
       "      <td>1.129475</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.250326</td>\n",
       "      <td>0.400251</td>\n",
       "      <td>-0.238680</td>\n",
       "      <td>-0.346375</td>\n",
       "      <td>1.485493</td>\n",
       "      <td>1.556699</td>\n",
       "      <td>0.470671</td>\n",
       "      <td>0.378581</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47345</th>\n",
       "      <td>-0.672105</td>\n",
       "      <td>-0.457813</td>\n",
       "      <td>-0.577140</td>\n",
       "      <td>-0.443123</td>\n",
       "      <td>-0.277865</td>\n",
       "      <td>-0.268501</td>\n",
       "      <td>-0.273671</td>\n",
       "      <td>0.728588</td>\n",
       "      <td>-0.684039</td>\n",
       "      <td>-0.147053</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.562720</td>\n",
       "      <td>-0.744570</td>\n",
       "      <td>-0.562649</td>\n",
       "      <td>-0.557806</td>\n",
       "      <td>-0.670339</td>\n",
       "      <td>-0.529202</td>\n",
       "      <td>-0.741186</td>\n",
       "      <td>-0.418623</td>\n",
       "      <td>MQTT_Flood</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47346 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       fwd_pkts_tot  bwd_pkts_tot  fwd_data_pkts_tot  bwd_data_pkts_tot  \\\n",
       "0         -0.236304     -0.662387          -0.577140          -0.443123   \n",
       "1         -0.672105     -0.457813          -0.577140          -0.443123   \n",
       "2         -0.454205     -0.662387          -0.577140          -0.443123   \n",
       "3          2.378496      2.406229           2.285759           2.444445   \n",
       "4         -0.672105     -0.457813          -0.577140          -0.443123   \n",
       "...             ...           ...                ...                ...   \n",
       "47341     -0.454205     -0.457813          -0.577140          -0.443123   \n",
       "47342     -0.454205     -0.662387          -0.577140          -0.443123   \n",
       "47343      2.160596      1.997080           2.285759           2.444445   \n",
       "47344      1.288996      1.383357           1.713179           0.711904   \n",
       "47345     -0.672105     -0.457813          -0.577140          -0.443123   \n",
       "\n",
       "       fwd_pkts_per_sec  bwd_pkts_per_sec  flow_pkts_per_sec  down_up_ratio  \\\n",
       "0             -0.277741         -0.268577          -0.273647      -1.394192   \n",
       "1              0.490111          0.504662           0.498222       0.728588   \n",
       "2             -0.277918         -0.268577          -0.273736      -1.394192   \n",
       "3             -0.276874         -0.267504          -0.272675       0.728588   \n",
       "4             -0.277823         -0.268460          -0.273629       0.728588   \n",
       "...                 ...               ...                ...            ...   \n",
       "47341         -0.276776         -0.267991          -0.272869      -0.332802   \n",
       "47342         -0.277509         -0.268577          -0.273530      -1.394192   \n",
       "47343         -0.276943         -0.267646          -0.272781       0.576960   \n",
       "47344         -0.265775         -0.256330          -0.261520       0.728588   \n",
       "47345         -0.277865         -0.268501          -0.273671       0.728588   \n",
       "\n",
       "       fwd_header_size_tot  fwd_header_size_min  ...  flow_pkts_payload.max  \\\n",
       "0                -0.643844            -1.423582  ...              -0.562720   \n",
       "1                -0.643844             0.278456  ...              -0.562720   \n",
       "2                -0.724235            -1.423582  ...              -0.562720   \n",
       "3                 2.129645            -0.147053  ...              -0.240860   \n",
       "4                -0.684039            -0.147053  ...              -0.562720   \n",
       "...                    ...                  ...  ...                    ...   \n",
       "47341            -0.483062            -0.147053  ...              -0.562720   \n",
       "47342            -0.724235            -1.423582  ...              -0.562720   \n",
       "47343             1.928668            -0.147053  ...              -0.240860   \n",
       "47344             2.330623             1.129475  ...              -0.250326   \n",
       "47345            -0.684039            -0.147053  ...              -0.562720   \n",
       "\n",
       "       flow_pkts_payload.tot  flow_pkts_payload.avg  flow_pkts_payload.std  \\\n",
       "0                  -0.744570              -0.562649              -0.557806   \n",
       "1                  -0.744570              -0.562649              -0.557806   \n",
       "2                  -0.744570              -0.562649              -0.557806   \n",
       "3                   1.678331              -0.105550              -0.268638   \n",
       "4                  -0.744570              -0.562649              -0.557806   \n",
       "...                      ...                    ...                    ...   \n",
       "47341              -0.744570              -0.562649              -0.557806   \n",
       "47342              -0.744570              -0.562649              -0.557806   \n",
       "47343               1.678331              -0.054762              -0.267306   \n",
       "47344               0.400251              -0.238680              -0.346375   \n",
       "47345              -0.744570              -0.562649              -0.557806   \n",
       "\n",
       "       fwd_subflow_pkts  bwd_subflow_pkts  fwd_subflow_bytes  \\\n",
       "0             -0.556874         -0.638986          -0.741186   \n",
       "1             -0.556874         -0.419418          -0.741186   \n",
       "2             -0.556874         -0.638986          -0.741186   \n",
       "3              2.620142          2.654541           1.265201   \n",
       "4             -0.670339         -0.529202          -0.741186   \n",
       "...                 ...               ...                ...   \n",
       "47341         -0.329944         -0.419418          -0.741186   \n",
       "47342         -0.556874         -0.638986          -0.741186   \n",
       "47343          0.275202          0.312477          -0.072391   \n",
       "47344          1.485493          1.556699           0.470671   \n",
       "47345         -0.670339         -0.529202          -0.741186   \n",
       "\n",
       "       bwd_subflow_bytes        traffic  is_attack  \n",
       "0              -0.418623      UDP_Flood          1  \n",
       "1              -0.418623  Port_Scanning          1  \n",
       "2              -0.418623      UDP_Flood          1  \n",
       "3               2.728235         Normal          0  \n",
       "4              -0.418623     MQTT_Flood          1  \n",
       "...                  ...            ...        ...  \n",
       "47341          -0.418623      TCP_Flood          1  \n",
       "47342          -0.418623      UDP_Flood          1  \n",
       "47343           0.630330         Normal          0  \n",
       "47344           0.378581         Normal          0  \n",
       "47345          -0.418623     MQTT_Flood          1  \n",
       "\n",
       "[47346 rows x 35 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"../../0_Datasets/Farm-Flow/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fwd_pkts_tot</th>\n",
       "      <th>bwd_pkts_tot</th>\n",
       "      <th>fwd_data_pkts_tot</th>\n",
       "      <th>bwd_data_pkts_tot</th>\n",
       "      <th>fwd_pkts_per_sec</th>\n",
       "      <th>bwd_pkts_per_sec</th>\n",
       "      <th>flow_pkts_per_sec</th>\n",
       "      <th>down_up_ratio</th>\n",
       "      <th>fwd_header_size_tot</th>\n",
       "      <th>fwd_header_size_min</th>\n",
       "      <th>...</th>\n",
       "      <th>flow_pkts_payload.max</th>\n",
       "      <th>flow_pkts_payload.tot</th>\n",
       "      <th>flow_pkts_payload.avg</th>\n",
       "      <th>flow_pkts_payload.std</th>\n",
       "      <th>fwd_subflow_pkts</th>\n",
       "      <th>bwd_subflow_pkts</th>\n",
       "      <th>fwd_subflow_bytes</th>\n",
       "      <th>bwd_subflow_bytes</th>\n",
       "      <th>traffic</th>\n",
       "      <th>is_attack</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.672105</td>\n",
       "      <td>-0.457813</td>\n",
       "      <td>-0.577140</td>\n",
       "      <td>-0.443123</td>\n",
       "      <td>-0.276940</td>\n",
       "      <td>-0.267571</td>\n",
       "      <td>-0.272742</td>\n",
       "      <td>0.728588</td>\n",
       "      <td>-0.684039</td>\n",
       "      <td>-0.147053</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.562720</td>\n",
       "      <td>-0.744570</td>\n",
       "      <td>-0.562649</td>\n",
       "      <td>-0.557806</td>\n",
       "      <td>-0.556874</td>\n",
       "      <td>-0.419418</td>\n",
       "      <td>-0.741186</td>\n",
       "      <td>-0.418623</td>\n",
       "      <td>MQTT_Flood</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.672105</td>\n",
       "      <td>-0.457813</td>\n",
       "      <td>-0.577140</td>\n",
       "      <td>-0.443123</td>\n",
       "      <td>-0.277181</td>\n",
       "      <td>-0.267813</td>\n",
       "      <td>-0.272983</td>\n",
       "      <td>0.728588</td>\n",
       "      <td>-0.684039</td>\n",
       "      <td>-0.147053</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.562720</td>\n",
       "      <td>-0.744570</td>\n",
       "      <td>-0.562649</td>\n",
       "      <td>-0.557806</td>\n",
       "      <td>-0.556874</td>\n",
       "      <td>-0.419418</td>\n",
       "      <td>-0.741186</td>\n",
       "      <td>-0.418623</td>\n",
       "      <td>MQTT_Flood</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.454205</td>\n",
       "      <td>-0.457813</td>\n",
       "      <td>-0.577140</td>\n",
       "      <td>-0.443123</td>\n",
       "      <td>-0.276909</td>\n",
       "      <td>-0.268058</td>\n",
       "      <td>-0.272969</td>\n",
       "      <td>-0.332802</td>\n",
       "      <td>-0.483062</td>\n",
       "      <td>-0.147053</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.562720</td>\n",
       "      <td>-0.744570</td>\n",
       "      <td>-0.562649</td>\n",
       "      <td>-0.557806</td>\n",
       "      <td>-0.329944</td>\n",
       "      <td>-0.419418</td>\n",
       "      <td>-0.741186</td>\n",
       "      <td>-0.418623</td>\n",
       "      <td>TCP_Flood</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.378496</td>\n",
       "      <td>2.406229</td>\n",
       "      <td>2.285759</td>\n",
       "      <td>2.444445</td>\n",
       "      <td>-0.276907</td>\n",
       "      <td>-0.267537</td>\n",
       "      <td>-0.272708</td>\n",
       "      <td>0.728588</td>\n",
       "      <td>2.129645</td>\n",
       "      <td>-0.147053</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.240860</td>\n",
       "      <td>1.678331</td>\n",
       "      <td>-0.105550</td>\n",
       "      <td>-0.268638</td>\n",
       "      <td>2.620142</td>\n",
       "      <td>2.654541</td>\n",
       "      <td>1.265201</td>\n",
       "      <td>2.728235</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.454205</td>\n",
       "      <td>-0.253238</td>\n",
       "      <td>-0.004560</td>\n",
       "      <td>-0.443123</td>\n",
       "      <td>-0.276892</td>\n",
       "      <td>-0.267522</td>\n",
       "      <td>-0.272693</td>\n",
       "      <td>0.728588</td>\n",
       "      <td>-0.241889</td>\n",
       "      <td>1.129475</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.477522</td>\n",
       "      <td>-0.635539</td>\n",
       "      <td>-0.408378</td>\n",
       "      <td>-0.455263</td>\n",
       "      <td>-0.329944</td>\n",
       "      <td>-0.199849</td>\n",
       "      <td>-0.596727</td>\n",
       "      <td>-0.418623</td>\n",
       "      <td>HTTP_Flood</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15778</th>\n",
       "      <td>1.942696</td>\n",
       "      <td>2.201655</td>\n",
       "      <td>2.285759</td>\n",
       "      <td>2.444445</td>\n",
       "      <td>-0.277003</td>\n",
       "      <td>-0.267561</td>\n",
       "      <td>-0.272768</td>\n",
       "      <td>0.891878</td>\n",
       "      <td>1.727690</td>\n",
       "      <td>-0.147053</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.240860</td>\n",
       "      <td>1.678331</td>\n",
       "      <td>-0.054762</td>\n",
       "      <td>-0.267306</td>\n",
       "      <td>0.691239</td>\n",
       "      <td>0.897993</td>\n",
       "      <td>0.262007</td>\n",
       "      <td>1.154806</td>\n",
       "      <td>Arp_Spoofing</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15779</th>\n",
       "      <td>2.160596</td>\n",
       "      <td>2.201655</td>\n",
       "      <td>2.285759</td>\n",
       "      <td>2.444445</td>\n",
       "      <td>-0.276991</td>\n",
       "      <td>-0.267622</td>\n",
       "      <td>-0.272793</td>\n",
       "      <td>0.728588</td>\n",
       "      <td>1.928668</td>\n",
       "      <td>-0.147053</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.240860</td>\n",
       "      <td>1.678331</td>\n",
       "      <td>-0.072901</td>\n",
       "      <td>-0.267431</td>\n",
       "      <td>2.393212</td>\n",
       "      <td>2.434972</td>\n",
       "      <td>1.265201</td>\n",
       "      <td>2.728235</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15780</th>\n",
       "      <td>-0.236304</td>\n",
       "      <td>-0.662387</td>\n",
       "      <td>-0.577140</td>\n",
       "      <td>-0.443123</td>\n",
       "      <td>-0.277906</td>\n",
       "      <td>-0.268577</td>\n",
       "      <td>-0.273730</td>\n",
       "      <td>-1.394192</td>\n",
       "      <td>-0.643844</td>\n",
       "      <td>-1.423582</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.562720</td>\n",
       "      <td>-0.744570</td>\n",
       "      <td>-0.562649</td>\n",
       "      <td>-0.557806</td>\n",
       "      <td>-0.556874</td>\n",
       "      <td>-0.638986</td>\n",
       "      <td>-0.741186</td>\n",
       "      <td>-0.418623</td>\n",
       "      <td>UDP_Flood</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15781</th>\n",
       "      <td>-0.454205</td>\n",
       "      <td>-0.662387</td>\n",
       "      <td>-0.577140</td>\n",
       "      <td>-0.443123</td>\n",
       "      <td>-0.277687</td>\n",
       "      <td>-0.268577</td>\n",
       "      <td>-0.273620</td>\n",
       "      <td>-1.394192</td>\n",
       "      <td>-0.724235</td>\n",
       "      <td>-1.423582</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.562720</td>\n",
       "      <td>-0.744570</td>\n",
       "      <td>-0.562649</td>\n",
       "      <td>-0.557806</td>\n",
       "      <td>-0.556874</td>\n",
       "      <td>-0.638986</td>\n",
       "      <td>-0.741186</td>\n",
       "      <td>-0.418623</td>\n",
       "      <td>UDP_Flood</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15782</th>\n",
       "      <td>-0.236304</td>\n",
       "      <td>-0.662387</td>\n",
       "      <td>-0.577140</td>\n",
       "      <td>-0.443123</td>\n",
       "      <td>-0.277882</td>\n",
       "      <td>-0.268577</td>\n",
       "      <td>-0.273718</td>\n",
       "      <td>-1.394192</td>\n",
       "      <td>-0.643844</td>\n",
       "      <td>-1.423582</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.562720</td>\n",
       "      <td>-0.744570</td>\n",
       "      <td>-0.562649</td>\n",
       "      <td>-0.557806</td>\n",
       "      <td>-0.556874</td>\n",
       "      <td>-0.638986</td>\n",
       "      <td>-0.741186</td>\n",
       "      <td>-0.418623</td>\n",
       "      <td>UDP_Flood</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15783 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       fwd_pkts_tot  bwd_pkts_tot  fwd_data_pkts_tot  bwd_data_pkts_tot  \\\n",
       "0         -0.672105     -0.457813          -0.577140          -0.443123   \n",
       "1         -0.672105     -0.457813          -0.577140          -0.443123   \n",
       "2         -0.454205     -0.457813          -0.577140          -0.443123   \n",
       "3          2.378496      2.406229           2.285759           2.444445   \n",
       "4         -0.454205     -0.253238          -0.004560          -0.443123   \n",
       "...             ...           ...                ...                ...   \n",
       "15778      1.942696      2.201655           2.285759           2.444445   \n",
       "15779      2.160596      2.201655           2.285759           2.444445   \n",
       "15780     -0.236304     -0.662387          -0.577140          -0.443123   \n",
       "15781     -0.454205     -0.662387          -0.577140          -0.443123   \n",
       "15782     -0.236304     -0.662387          -0.577140          -0.443123   \n",
       "\n",
       "       fwd_pkts_per_sec  bwd_pkts_per_sec  flow_pkts_per_sec  down_up_ratio  \\\n",
       "0             -0.276940         -0.267571          -0.272742       0.728588   \n",
       "1             -0.277181         -0.267813          -0.272983       0.728588   \n",
       "2             -0.276909         -0.268058          -0.272969      -0.332802   \n",
       "3             -0.276907         -0.267537          -0.272708       0.728588   \n",
       "4             -0.276892         -0.267522          -0.272693       0.728588   \n",
       "...                 ...               ...                ...            ...   \n",
       "15778         -0.277003         -0.267561          -0.272768       0.891878   \n",
       "15779         -0.276991         -0.267622          -0.272793       0.728588   \n",
       "15780         -0.277906         -0.268577          -0.273730      -1.394192   \n",
       "15781         -0.277687         -0.268577          -0.273620      -1.394192   \n",
       "15782         -0.277882         -0.268577          -0.273718      -1.394192   \n",
       "\n",
       "       fwd_header_size_tot  fwd_header_size_min  ...  flow_pkts_payload.max  \\\n",
       "0                -0.684039            -0.147053  ...              -0.562720   \n",
       "1                -0.684039            -0.147053  ...              -0.562720   \n",
       "2                -0.483062            -0.147053  ...              -0.562720   \n",
       "3                 2.129645            -0.147053  ...              -0.240860   \n",
       "4                -0.241889             1.129475  ...              -0.477522   \n",
       "...                    ...                  ...  ...                    ...   \n",
       "15778             1.727690            -0.147053  ...              -0.240860   \n",
       "15779             1.928668            -0.147053  ...              -0.240860   \n",
       "15780            -0.643844            -1.423582  ...              -0.562720   \n",
       "15781            -0.724235            -1.423582  ...              -0.562720   \n",
       "15782            -0.643844            -1.423582  ...              -0.562720   \n",
       "\n",
       "       flow_pkts_payload.tot  flow_pkts_payload.avg  flow_pkts_payload.std  \\\n",
       "0                  -0.744570              -0.562649              -0.557806   \n",
       "1                  -0.744570              -0.562649              -0.557806   \n",
       "2                  -0.744570              -0.562649              -0.557806   \n",
       "3                   1.678331              -0.105550              -0.268638   \n",
       "4                  -0.635539              -0.408378              -0.455263   \n",
       "...                      ...                    ...                    ...   \n",
       "15778               1.678331              -0.054762              -0.267306   \n",
       "15779               1.678331              -0.072901              -0.267431   \n",
       "15780              -0.744570              -0.562649              -0.557806   \n",
       "15781              -0.744570              -0.562649              -0.557806   \n",
       "15782              -0.744570              -0.562649              -0.557806   \n",
       "\n",
       "       fwd_subflow_pkts  bwd_subflow_pkts  fwd_subflow_bytes  \\\n",
       "0             -0.556874         -0.419418          -0.741186   \n",
       "1             -0.556874         -0.419418          -0.741186   \n",
       "2             -0.329944         -0.419418          -0.741186   \n",
       "3              2.620142          2.654541           1.265201   \n",
       "4             -0.329944         -0.199849          -0.596727   \n",
       "...                 ...               ...                ...   \n",
       "15778          0.691239          0.897993           0.262007   \n",
       "15779          2.393212          2.434972           1.265201   \n",
       "15780         -0.556874         -0.638986          -0.741186   \n",
       "15781         -0.556874         -0.638986          -0.741186   \n",
       "15782         -0.556874         -0.638986          -0.741186   \n",
       "\n",
       "       bwd_subflow_bytes       traffic  is_attack  \n",
       "0              -0.418623    MQTT_Flood          1  \n",
       "1              -0.418623    MQTT_Flood          1  \n",
       "2              -0.418623     TCP_Flood          1  \n",
       "3               2.728235        Normal          0  \n",
       "4              -0.418623    HTTP_Flood          1  \n",
       "...                  ...           ...        ...  \n",
       "15778           1.154806  Arp_Spoofing          1  \n",
       "15779           2.728235        Normal          0  \n",
       "15780          -0.418623     UDP_Flood          1  \n",
       "15781          -0.418623     UDP_Flood          1  \n",
       "15782          -0.418623     UDP_Flood          1  \n",
       "\n",
       "[15783 rows x 35 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "## Train and Test Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop Multiclass Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.drop('traffic', axis=1)\n",
    "df_test = df_test.drop('traffic', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excluding the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_columns = df_train.columns.drop('is_attack')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a feature matrix X by selecting only the columns specified in X_columns. Then convert the selected data into a NumPy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train[X_columns].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creates a target variable y containing the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_train[\"is_attack\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Previous Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved Random Forest model\n",
    "model_folder = \"../../2_Modeling_Phase/Saved-Models/\"\n",
    "model_filename = \"Farm-Flow_RF_Random_Forest_Model.joblib\"\n",
    "model_path = model_folder + model_filename\n",
    "\n",
    "model = joblib.load(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get Features Names and Class Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = list(X_columns)\n",
    "class_names = [\"Normal\", \"Malicious\"]\n",
    "response_dict = {0: 'Normal', 1: 'Malicious'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Labeled Df's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_labeled = pd.DataFrame(X_test, columns=feature_names)\n",
    "X_train_labeled = pd.DataFrame(X_train, columns=feature_names)\n",
    "\n",
    "# Since both are one-dimensional NumPy arrays\n",
    "pred_series = pd.Series(pred)\n",
    "y_test_target_series = pd.Series(y_test)\n",
    "y_train_target_series = pd.Series(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a subset of the Train DF for faster training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_percentage = 0.1\n",
    "X_subset, _, y_subset, _ = train_test_split(X_train, y_train, test_size=1 - subset_percentage, stratify=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_percentage = 0.1\n",
    "X_subset_labeled, _, y_subset_labeled, _ = train_test_split(X_train_labeled, y_train_target_series, test_size=1 - subset_percentage, stratify=y_train_target_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Row to explain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## LOFO (Leave One Feature Out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How it works\n",
    "LOFO (Leave One Feature Out) Importance calculates the importances of a set of features based on a metric of choice, for a model of choice, by iteratively removing each feature from the set, and evaluating the performance of the model, with a validation scheme of choice, based on the chosen metric.\n",
    "\n",
    "LOFO first evaluates the performance of the model with all the input features included, then iteratively removes one feature at a time, retrains the model, and evaluates its performance on a validation set. The mean and standard deviation (across the folds) of the importance of each feature is then reported.\n",
    "\n",
    "If a model is not passed as an argument to LOFO Importance, it will run LightGBM as a default model.\n",
    "\n",
    "### How it applys\n",
    "Understand the feature importance of the dataset\n",
    "\n",
    "### Repository:\n",
    "- https://github.com/aerdem4/lofo-importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install lofo-importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fwd_pkts_tot</th>\n",
       "      <th>bwd_pkts_tot</th>\n",
       "      <th>fwd_data_pkts_tot</th>\n",
       "      <th>bwd_data_pkts_tot</th>\n",
       "      <th>fwd_pkts_per_sec</th>\n",
       "      <th>bwd_pkts_per_sec</th>\n",
       "      <th>flow_pkts_per_sec</th>\n",
       "      <th>down_up_ratio</th>\n",
       "      <th>fwd_header_size_tot</th>\n",
       "      <th>fwd_header_size_min</th>\n",
       "      <th>...</th>\n",
       "      <th>flow_pkts_payload.min</th>\n",
       "      <th>flow_pkts_payload.max</th>\n",
       "      <th>flow_pkts_payload.tot</th>\n",
       "      <th>flow_pkts_payload.avg</th>\n",
       "      <th>flow_pkts_payload.std</th>\n",
       "      <th>fwd_subflow_pkts</th>\n",
       "      <th>bwd_subflow_pkts</th>\n",
       "      <th>fwd_subflow_bytes</th>\n",
       "      <th>bwd_subflow_bytes</th>\n",
       "      <th>is_attack</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.236304</td>\n",
       "      <td>-0.662387</td>\n",
       "      <td>-0.577140</td>\n",
       "      <td>-0.443123</td>\n",
       "      <td>-0.277741</td>\n",
       "      <td>-0.268577</td>\n",
       "      <td>-0.273647</td>\n",
       "      <td>-1.394192</td>\n",
       "      <td>-0.643844</td>\n",
       "      <td>-1.423582</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.022646</td>\n",
       "      <td>-0.562720</td>\n",
       "      <td>-0.744570</td>\n",
       "      <td>-0.562649</td>\n",
       "      <td>-0.557806</td>\n",
       "      <td>-0.556874</td>\n",
       "      <td>-0.638986</td>\n",
       "      <td>-0.741186</td>\n",
       "      <td>-0.418623</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.672105</td>\n",
       "      <td>-0.457813</td>\n",
       "      <td>-0.577140</td>\n",
       "      <td>-0.443123</td>\n",
       "      <td>0.490111</td>\n",
       "      <td>0.504662</td>\n",
       "      <td>0.498222</td>\n",
       "      <td>0.728588</td>\n",
       "      <td>-0.643844</td>\n",
       "      <td>0.278456</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.022646</td>\n",
       "      <td>-0.562720</td>\n",
       "      <td>-0.744570</td>\n",
       "      <td>-0.562649</td>\n",
       "      <td>-0.557806</td>\n",
       "      <td>-0.556874</td>\n",
       "      <td>-0.419418</td>\n",
       "      <td>-0.741186</td>\n",
       "      <td>-0.418623</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.454205</td>\n",
       "      <td>-0.662387</td>\n",
       "      <td>-0.577140</td>\n",
       "      <td>-0.443123</td>\n",
       "      <td>-0.277918</td>\n",
       "      <td>-0.268577</td>\n",
       "      <td>-0.273736</td>\n",
       "      <td>-1.394192</td>\n",
       "      <td>-0.724235</td>\n",
       "      <td>-1.423582</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.022646</td>\n",
       "      <td>-0.562720</td>\n",
       "      <td>-0.744570</td>\n",
       "      <td>-0.562649</td>\n",
       "      <td>-0.557806</td>\n",
       "      <td>-0.556874</td>\n",
       "      <td>-0.638986</td>\n",
       "      <td>-0.741186</td>\n",
       "      <td>-0.418623</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.378496</td>\n",
       "      <td>2.406229</td>\n",
       "      <td>2.285759</td>\n",
       "      <td>2.444445</td>\n",
       "      <td>-0.276874</td>\n",
       "      <td>-0.267504</td>\n",
       "      <td>-0.272675</td>\n",
       "      <td>0.728588</td>\n",
       "      <td>2.129645</td>\n",
       "      <td>-0.147053</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.022646</td>\n",
       "      <td>-0.240860</td>\n",
       "      <td>1.678331</td>\n",
       "      <td>-0.105550</td>\n",
       "      <td>-0.268638</td>\n",
       "      <td>2.620142</td>\n",
       "      <td>2.654541</td>\n",
       "      <td>1.265201</td>\n",
       "      <td>2.728235</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.672105</td>\n",
       "      <td>-0.457813</td>\n",
       "      <td>-0.577140</td>\n",
       "      <td>-0.443123</td>\n",
       "      <td>-0.277823</td>\n",
       "      <td>-0.268460</td>\n",
       "      <td>-0.273629</td>\n",
       "      <td>0.728588</td>\n",
       "      <td>-0.684039</td>\n",
       "      <td>-0.147053</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.022646</td>\n",
       "      <td>-0.562720</td>\n",
       "      <td>-0.744570</td>\n",
       "      <td>-0.562649</td>\n",
       "      <td>-0.557806</td>\n",
       "      <td>-0.670339</td>\n",
       "      <td>-0.529202</td>\n",
       "      <td>-0.741186</td>\n",
       "      <td>-0.418623</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47341</th>\n",
       "      <td>-0.454205</td>\n",
       "      <td>-0.457813</td>\n",
       "      <td>-0.577140</td>\n",
       "      <td>-0.443123</td>\n",
       "      <td>-0.276776</td>\n",
       "      <td>-0.267991</td>\n",
       "      <td>-0.272869</td>\n",
       "      <td>-0.332802</td>\n",
       "      <td>-0.483062</td>\n",
       "      <td>-0.147053</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.022646</td>\n",
       "      <td>-0.562720</td>\n",
       "      <td>-0.744570</td>\n",
       "      <td>-0.562649</td>\n",
       "      <td>-0.557806</td>\n",
       "      <td>-0.329944</td>\n",
       "      <td>-0.419418</td>\n",
       "      <td>-0.741186</td>\n",
       "      <td>-0.418623</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47342</th>\n",
       "      <td>-0.454205</td>\n",
       "      <td>-0.662387</td>\n",
       "      <td>-0.577140</td>\n",
       "      <td>-0.443123</td>\n",
       "      <td>-0.277509</td>\n",
       "      <td>-0.268577</td>\n",
       "      <td>-0.273530</td>\n",
       "      <td>-1.394192</td>\n",
       "      <td>-0.724235</td>\n",
       "      <td>-1.423582</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.022646</td>\n",
       "      <td>-0.562720</td>\n",
       "      <td>-0.744570</td>\n",
       "      <td>-0.562649</td>\n",
       "      <td>-0.557806</td>\n",
       "      <td>-0.556874</td>\n",
       "      <td>-0.638986</td>\n",
       "      <td>-0.741186</td>\n",
       "      <td>-0.418623</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47343</th>\n",
       "      <td>2.160596</td>\n",
       "      <td>1.997080</td>\n",
       "      <td>2.285759</td>\n",
       "      <td>2.444445</td>\n",
       "      <td>-0.276943</td>\n",
       "      <td>-0.267646</td>\n",
       "      <td>-0.272781</td>\n",
       "      <td>0.576960</td>\n",
       "      <td>1.928668</td>\n",
       "      <td>-0.147053</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.022646</td>\n",
       "      <td>-0.240860</td>\n",
       "      <td>1.678331</td>\n",
       "      <td>-0.054762</td>\n",
       "      <td>-0.267306</td>\n",
       "      <td>0.275202</td>\n",
       "      <td>0.312477</td>\n",
       "      <td>-0.072391</td>\n",
       "      <td>0.630330</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47344</th>\n",
       "      <td>1.288996</td>\n",
       "      <td>1.383357</td>\n",
       "      <td>1.713179</td>\n",
       "      <td>0.711904</td>\n",
       "      <td>-0.265775</td>\n",
       "      <td>-0.256330</td>\n",
       "      <td>-0.261520</td>\n",
       "      <td>0.728588</td>\n",
       "      <td>2.330623</td>\n",
       "      <td>1.129475</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.022646</td>\n",
       "      <td>-0.250326</td>\n",
       "      <td>0.400251</td>\n",
       "      <td>-0.238680</td>\n",
       "      <td>-0.346375</td>\n",
       "      <td>1.485493</td>\n",
       "      <td>1.556699</td>\n",
       "      <td>0.470671</td>\n",
       "      <td>0.378581</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47345</th>\n",
       "      <td>-0.672105</td>\n",
       "      <td>-0.457813</td>\n",
       "      <td>-0.577140</td>\n",
       "      <td>-0.443123</td>\n",
       "      <td>-0.277865</td>\n",
       "      <td>-0.268501</td>\n",
       "      <td>-0.273671</td>\n",
       "      <td>0.728588</td>\n",
       "      <td>-0.684039</td>\n",
       "      <td>-0.147053</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.022646</td>\n",
       "      <td>-0.562720</td>\n",
       "      <td>-0.744570</td>\n",
       "      <td>-0.562649</td>\n",
       "      <td>-0.557806</td>\n",
       "      <td>-0.670339</td>\n",
       "      <td>-0.529202</td>\n",
       "      <td>-0.741186</td>\n",
       "      <td>-0.418623</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47346 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       fwd_pkts_tot  bwd_pkts_tot  fwd_data_pkts_tot  bwd_data_pkts_tot  \\\n",
       "0         -0.236304     -0.662387          -0.577140          -0.443123   \n",
       "1         -0.672105     -0.457813          -0.577140          -0.443123   \n",
       "2         -0.454205     -0.662387          -0.577140          -0.443123   \n",
       "3          2.378496      2.406229           2.285759           2.444445   \n",
       "4         -0.672105     -0.457813          -0.577140          -0.443123   \n",
       "...             ...           ...                ...                ...   \n",
       "47341     -0.454205     -0.457813          -0.577140          -0.443123   \n",
       "47342     -0.454205     -0.662387          -0.577140          -0.443123   \n",
       "47343      2.160596      1.997080           2.285759           2.444445   \n",
       "47344      1.288996      1.383357           1.713179           0.711904   \n",
       "47345     -0.672105     -0.457813          -0.577140          -0.443123   \n",
       "\n",
       "       fwd_pkts_per_sec  bwd_pkts_per_sec  flow_pkts_per_sec  down_up_ratio  \\\n",
       "0             -0.277741         -0.268577          -0.273647      -1.394192   \n",
       "1              0.490111          0.504662           0.498222       0.728588   \n",
       "2             -0.277918         -0.268577          -0.273736      -1.394192   \n",
       "3             -0.276874         -0.267504          -0.272675       0.728588   \n",
       "4             -0.277823         -0.268460          -0.273629       0.728588   \n",
       "...                 ...               ...                ...            ...   \n",
       "47341         -0.276776         -0.267991          -0.272869      -0.332802   \n",
       "47342         -0.277509         -0.268577          -0.273530      -1.394192   \n",
       "47343         -0.276943         -0.267646          -0.272781       0.576960   \n",
       "47344         -0.265775         -0.256330          -0.261520       0.728588   \n",
       "47345         -0.277865         -0.268501          -0.273671       0.728588   \n",
       "\n",
       "       fwd_header_size_tot  fwd_header_size_min  ...  flow_pkts_payload.min  \\\n",
       "0                -0.643844            -1.423582  ...              -0.022646   \n",
       "1                -0.643844             0.278456  ...              -0.022646   \n",
       "2                -0.724235            -1.423582  ...              -0.022646   \n",
       "3                 2.129645            -0.147053  ...              -0.022646   \n",
       "4                -0.684039            -0.147053  ...              -0.022646   \n",
       "...                    ...                  ...  ...                    ...   \n",
       "47341            -0.483062            -0.147053  ...              -0.022646   \n",
       "47342            -0.724235            -1.423582  ...              -0.022646   \n",
       "47343             1.928668            -0.147053  ...              -0.022646   \n",
       "47344             2.330623             1.129475  ...              -0.022646   \n",
       "47345            -0.684039            -0.147053  ...              -0.022646   \n",
       "\n",
       "       flow_pkts_payload.max  flow_pkts_payload.tot  flow_pkts_payload.avg  \\\n",
       "0                  -0.562720              -0.744570              -0.562649   \n",
       "1                  -0.562720              -0.744570              -0.562649   \n",
       "2                  -0.562720              -0.744570              -0.562649   \n",
       "3                  -0.240860               1.678331              -0.105550   \n",
       "4                  -0.562720              -0.744570              -0.562649   \n",
       "...                      ...                    ...                    ...   \n",
       "47341              -0.562720              -0.744570              -0.562649   \n",
       "47342              -0.562720              -0.744570              -0.562649   \n",
       "47343              -0.240860               1.678331              -0.054762   \n",
       "47344              -0.250326               0.400251              -0.238680   \n",
       "47345              -0.562720              -0.744570              -0.562649   \n",
       "\n",
       "       flow_pkts_payload.std  fwd_subflow_pkts  bwd_subflow_pkts  \\\n",
       "0                  -0.557806         -0.556874         -0.638986   \n",
       "1                  -0.557806         -0.556874         -0.419418   \n",
       "2                  -0.557806         -0.556874         -0.638986   \n",
       "3                  -0.268638          2.620142          2.654541   \n",
       "4                  -0.557806         -0.670339         -0.529202   \n",
       "...                      ...               ...               ...   \n",
       "47341              -0.557806         -0.329944         -0.419418   \n",
       "47342              -0.557806         -0.556874         -0.638986   \n",
       "47343              -0.267306          0.275202          0.312477   \n",
       "47344              -0.346375          1.485493          1.556699   \n",
       "47345              -0.557806         -0.670339         -0.529202   \n",
       "\n",
       "       fwd_subflow_bytes  bwd_subflow_bytes  is_attack  \n",
       "0              -0.741186          -0.418623        1.0  \n",
       "1              -0.741186          -0.418623        1.0  \n",
       "2              -0.741186          -0.418623        1.0  \n",
       "3               1.265201           2.728235        0.0  \n",
       "4              -0.741186          -0.418623        1.0  \n",
       "...                  ...                ...        ...  \n",
       "47341          -0.741186          -0.418623        1.0  \n",
       "47342          -0.741186          -0.418623        1.0  \n",
       "47343          -0.072391           0.630330        0.0  \n",
       "47344           0.470671           0.378581        0.0  \n",
       "47345          -0.741186          -0.418623        1.0  \n",
       "\n",
       "[47346 rows x 34 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_data = np.column_stack((X, y))\n",
    "\n",
    "features_names = [f\"{feature_names[i]}\" for i in range(X_train_labeled.shape[1])]\n",
    "target_name = \"is_attack\"\n",
    "\n",
    "column_names = features_names + [target_name]\n",
    "\n",
    "combined_df = pd.DataFrame(combined_data, columns=column_names)\n",
    "\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ivoafonsobispo\\anaconda3\\Lib\\site-packages\\lofo\\lofo_importance.py:3: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "from lofo import LOFOImportance, Dataset, plot_importance\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 237, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000153 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 750\n",
      "[LightGBM] [Info] Number of data points in the train set: 354, number of used features: 31\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.669492 -> initscore=0.705886\n",
      "[LightGBM] [Info] Start training from score 0.705886\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 236, number of negative: 119\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000112 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 781\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 31\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.664789 -> initscore=0.684708\n",
      "[LightGBM] [Info] Start training from score 0.684708\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 237, number of negative: 118\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000140 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 756\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 31\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.667606 -> initscore=0.697376\n",
      "[LightGBM] [Info] Start training from score 0.697376\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 238, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000138 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 778\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 31\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.670423 -> initscore=0.710097\n",
      "[LightGBM] [Info] Start training from score 0.710097\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "607e93e74fe14df2b0d9171a5e42264b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 237, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000073 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 733\n",
      "[LightGBM] [Info] Number of data points in the train set: 354, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.669492 -> initscore=0.705886\n",
      "[LightGBM] [Info] Start training from score 0.705886\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 236, number of negative: 119\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000130 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.664789 -> initscore=0.684708\n",
      "[LightGBM] [Info] Start training from score 0.684708\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 237, number of negative: 118\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000142 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 737\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.667606 -> initscore=0.697376\n",
      "[LightGBM] [Info] Start training from score 0.697376\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 238, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000165 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 759\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.670423 -> initscore=0.710097\n",
      "[LightGBM] [Info] Start training from score 0.710097\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 237, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000117 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 738\n",
      "[LightGBM] [Info] Number of data points in the train set: 354, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.669492 -> initscore=0.705886\n",
      "[LightGBM] [Info] Start training from score 0.705886\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 236, number of negative: 119\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000140 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 769\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.664789 -> initscore=0.684708\n",
      "[LightGBM] [Info] Start training from score 0.684708\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 237, number of negative: 118\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000107 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 744\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.667606 -> initscore=0.697376\n",
      "[LightGBM] [Info] Start training from score 0.697376\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 238, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000154 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.670423 -> initscore=0.710097\n",
      "[LightGBM] [Info] Start training from score 0.710097\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 237, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000119 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 631\n",
      "[LightGBM] [Info] Number of data points in the train set: 354, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.669492 -> initscore=0.705886\n",
      "[LightGBM] [Info] Start training from score 0.705886\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 236, number of negative: 119\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000136 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 662\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.664789 -> initscore=0.684708\n",
      "[LightGBM] [Info] Start training from score 0.684708\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 237, number of negative: 118\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000166 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 637\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.667606 -> initscore=0.697376\n",
      "[LightGBM] [Info] Start training from score 0.697376\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 238, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000149 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 659\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.670423 -> initscore=0.710097\n",
      "[LightGBM] [Info] Start training from score 0.710097\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 237, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000141 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 732\n",
      "[LightGBM] [Info] Number of data points in the train set: 354, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.669492 -> initscore=0.705886\n",
      "[LightGBM] [Info] Start training from score 0.705886\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 236, number of negative: 119\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000119 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 761\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.664789 -> initscore=0.684708\n",
      "[LightGBM] [Info] Start training from score 0.684708\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 237, number of negative: 118\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000115 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 736\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.667606 -> initscore=0.697376\n",
      "[LightGBM] [Info] Start training from score 0.697376\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 238, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000132 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 759\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.670423 -> initscore=0.710097\n",
      "[LightGBM] [Info] Start training from score 0.710097\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 237, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000159 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 741\n",
      "[LightGBM] [Info] Number of data points in the train set: 354, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.669492 -> initscore=0.705886\n",
      "[LightGBM] [Info] Start training from score 0.705886\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 236, number of negative: 119\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000136 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 771\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.664789 -> initscore=0.684708\n",
      "[LightGBM] [Info] Start training from score 0.684708\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 237, number of negative: 118\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000138 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 747\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.667606 -> initscore=0.697376\n",
      "[LightGBM] [Info] Start training from score 0.697376\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 238, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000137 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 769\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.670423 -> initscore=0.710097\n",
      "[LightGBM] [Info] Start training from score 0.710097\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 237, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000160 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 745\n",
      "[LightGBM] [Info] Number of data points in the train set: 354, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.669492 -> initscore=0.705886\n",
      "[LightGBM] [Info] Start training from score 0.705886\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 236, number of negative: 119\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000140 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 776\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.664789 -> initscore=0.684708\n",
      "[LightGBM] [Info] Start training from score 0.684708\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 237, number of negative: 118\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000115 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 751\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.667606 -> initscore=0.697376\n",
      "[LightGBM] [Info] Start training from score 0.697376\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 238, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000112 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 773\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.670423 -> initscore=0.710097\n",
      "[LightGBM] [Info] Start training from score 0.710097\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 237, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000160 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 722\n",
      "[LightGBM] [Info] Number of data points in the train set: 354, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.669492 -> initscore=0.705886\n",
      "[LightGBM] [Info] Start training from score 0.705886\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 236, number of negative: 119\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000109 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 750\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.664789 -> initscore=0.684708\n",
      "[LightGBM] [Info] Start training from score 0.684708\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 237, number of negative: 118\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000143 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 730\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.667606 -> initscore=0.697376\n",
      "[LightGBM] [Info] Start training from score 0.697376\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 238, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000109 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 749\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.670423 -> initscore=0.710097\n",
      "[LightGBM] [Info] Start training from score 0.710097\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 237, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000123 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 740\n",
      "[LightGBM] [Info] Number of data points in the train set: 354, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.669492 -> initscore=0.705886\n",
      "[LightGBM] [Info] Start training from score 0.705886\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 236, number of negative: 119\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000104 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 771\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.664789 -> initscore=0.684708\n",
      "[LightGBM] [Info] Start training from score 0.684708\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 237, number of negative: 118\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000138 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 746\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.667606 -> initscore=0.697376\n",
      "[LightGBM] [Info] Start training from score 0.697376\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 238, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000106 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 768\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.670423 -> initscore=0.710097\n",
      "[LightGBM] [Info] Start training from score 0.710097\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 237, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000160 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 731\n",
      "[LightGBM] [Info] Number of data points in the train set: 354, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.669492 -> initscore=0.705886\n",
      "[LightGBM] [Info] Start training from score 0.705886\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 236, number of negative: 119\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000146 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 761\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.664789 -> initscore=0.684708\n",
      "[LightGBM] [Info] Start training from score 0.684708\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 237, number of negative: 118\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000111 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 737\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.667606 -> initscore=0.697376\n",
      "[LightGBM] [Info] Start training from score 0.697376\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 238, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000118 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 757\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.670423 -> initscore=0.710097\n",
      "[LightGBM] [Info] Start training from score 0.710097\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 237, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000150 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 732\n",
      "[LightGBM] [Info] Number of data points in the train set: 354, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.669492 -> initscore=0.705886\n",
      "[LightGBM] [Info] Start training from score 0.705886\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 236, number of negative: 119\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000146 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 763\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.664789 -> initscore=0.684708\n",
      "[LightGBM] [Info] Start training from score 0.684708\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 237, number of negative: 118\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000124 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 736\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.667606 -> initscore=0.697376\n",
      "[LightGBM] [Info] Start training from score 0.697376\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 238, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000143 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 760\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.670423 -> initscore=0.710097\n",
      "[LightGBM] [Info] Start training from score 0.710097\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 237, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000150 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 743\n",
      "[LightGBM] [Info] Number of data points in the train set: 354, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.669492 -> initscore=0.705886\n",
      "[LightGBM] [Info] Start training from score 0.705886\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 236, number of negative: 119\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000113 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 774\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.664789 -> initscore=0.684708\n",
      "[LightGBM] [Info] Start training from score 0.684708\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 237, number of negative: 118\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000119 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 748\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.667606 -> initscore=0.697376\n",
      "[LightGBM] [Info] Start training from score 0.697376\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 238, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000126 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 770\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.670423 -> initscore=0.710097\n",
      "[LightGBM] [Info] Start training from score 0.710097\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 237, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000166 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 724\n",
      "[LightGBM] [Info] Number of data points in the train set: 354, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.669492 -> initscore=0.705886\n",
      "[LightGBM] [Info] Start training from score 0.705886\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 236, number of negative: 119\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000121 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 752\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.664789 -> initscore=0.684708\n",
      "[LightGBM] [Info] Start training from score 0.684708\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 237, number of negative: 118\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000160 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 729\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.667606 -> initscore=0.697376\n",
      "[LightGBM] [Info] Start training from score 0.697376\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 238, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000110 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 748\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.670423 -> initscore=0.710097\n",
      "[LightGBM] [Info] Start training from score 0.710097\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 237, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000133 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 735\n",
      "[LightGBM] [Info] Number of data points in the train set: 354, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.669492 -> initscore=0.705886\n",
      "[LightGBM] [Info] Start training from score 0.705886\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 236, number of negative: 119\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000111 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 763\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.664789 -> initscore=0.684708\n",
      "[LightGBM] [Info] Start training from score 0.684708\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 237, number of negative: 118\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000139 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 739\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.667606 -> initscore=0.697376\n",
      "[LightGBM] [Info] Start training from score 0.697376\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 238, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000148 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 761\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.670423 -> initscore=0.710097\n",
      "[LightGBM] [Info] Start training from score 0.710097\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 237, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000158 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 743\n",
      "[LightGBM] [Info] Number of data points in the train set: 354, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.669492 -> initscore=0.705886\n",
      "[LightGBM] [Info] Start training from score 0.705886\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 236, number of negative: 119\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000116 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 774\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.664789 -> initscore=0.684708\n",
      "[LightGBM] [Info] Start training from score 0.684708\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 237, number of negative: 118\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000172 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 750\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.667606 -> initscore=0.697376\n",
      "[LightGBM] [Info] Start training from score 0.697376\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 238, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000149 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 771\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.670423 -> initscore=0.710097\n",
      "[LightGBM] [Info] Start training from score 0.710097\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 237, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000189 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 739\n",
      "[LightGBM] [Info] Number of data points in the train set: 354, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.669492 -> initscore=0.705886\n",
      "[LightGBM] [Info] Start training from score 0.705886\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 236, number of negative: 119\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000121 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 769\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.664789 -> initscore=0.684708\n",
      "[LightGBM] [Info] Start training from score 0.684708\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 237, number of negative: 118\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000112 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 745\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.667606 -> initscore=0.697376\n",
      "[LightGBM] [Info] Start training from score 0.697376\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 238, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000119 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 766\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.670423 -> initscore=0.710097\n",
      "[LightGBM] [Info] Start training from score 0.710097\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 237, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000123 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 741\n",
      "[LightGBM] [Info] Number of data points in the train set: 354, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.669492 -> initscore=0.705886\n",
      "[LightGBM] [Info] Start training from score 0.705886\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 236, number of negative: 119\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000149 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 770\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.664789 -> initscore=0.684708\n",
      "[LightGBM] [Info] Start training from score 0.684708\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 237, number of negative: 118\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000150 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 746\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.667606 -> initscore=0.697376\n",
      "[LightGBM] [Info] Start training from score 0.697376\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 238, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000118 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 767\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.670423 -> initscore=0.710097\n",
      "[LightGBM] [Info] Start training from score 0.710097\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 237, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000166 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 743\n",
      "[LightGBM] [Info] Number of data points in the train set: 354, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.669492 -> initscore=0.705886\n",
      "[LightGBM] [Info] Start training from score 0.705886\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 236, number of negative: 119\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000153 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 774\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.664789 -> initscore=0.684708\n",
      "[LightGBM] [Info] Start training from score 0.684708\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 237, number of negative: 118\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000148 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 749\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.667606 -> initscore=0.697376\n",
      "[LightGBM] [Info] Start training from score 0.697376\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 238, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000144 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 771\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.670423 -> initscore=0.710097\n",
      "[LightGBM] [Info] Start training from score 0.710097\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 237, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000130 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 729\n",
      "[LightGBM] [Info] Number of data points in the train set: 354, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.669492 -> initscore=0.705886\n",
      "[LightGBM] [Info] Start training from score 0.705886\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 236, number of negative: 119\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000152 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 758\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.664789 -> initscore=0.684708\n",
      "[LightGBM] [Info] Start training from score 0.684708\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 237, number of negative: 118\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000147 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 737\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.667606 -> initscore=0.697376\n",
      "[LightGBM] [Info] Start training from score 0.697376\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 238, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000115 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 758\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.670423 -> initscore=0.710097\n",
      "[LightGBM] [Info] Start training from score 0.710097\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 237, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000158 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 743\n",
      "[LightGBM] [Info] Number of data points in the train set: 354, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.669492 -> initscore=0.705886\n",
      "[LightGBM] [Info] Start training from score 0.705886\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 236, number of negative: 119\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000147 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 775\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.664789 -> initscore=0.684708\n",
      "[LightGBM] [Info] Start training from score 0.684708\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 237, number of negative: 118\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000163 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 749\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.667606 -> initscore=0.697376\n",
      "[LightGBM] [Info] Start training from score 0.697376\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 238, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000141 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 772\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.670423 -> initscore=0.710097\n",
      "[LightGBM] [Info] Start training from score 0.710097\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 237, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000177 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 631\n",
      "[LightGBM] [Info] Number of data points in the train set: 354, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.669492 -> initscore=0.705886\n",
      "[LightGBM] [Info] Start training from score 0.705886\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 236, number of negative: 119\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000151 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 662\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.664789 -> initscore=0.684708\n",
      "[LightGBM] [Info] Start training from score 0.684708\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 237, number of negative: 118\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000105 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 637\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.667606 -> initscore=0.697376\n",
      "[LightGBM] [Info] Start training from score 0.697376\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 238, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000147 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 659\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.670423 -> initscore=0.710097\n",
      "[LightGBM] [Info] Start training from score 0.710097\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 237, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000165 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 727\n",
      "[LightGBM] [Info] Number of data points in the train set: 354, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.669492 -> initscore=0.705886\n",
      "[LightGBM] [Info] Start training from score 0.705886\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 236, number of negative: 119\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000137 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 757\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.664789 -> initscore=0.684708\n",
      "[LightGBM] [Info] Start training from score 0.684708\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 237, number of negative: 118\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000158 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 734\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.667606 -> initscore=0.697376\n",
      "[LightGBM] [Info] Start training from score 0.697376\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 238, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000147 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 752\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.670423 -> initscore=0.710097\n",
      "[LightGBM] [Info] Start training from score 0.710097\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 237, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000124 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 737\n",
      "[LightGBM] [Info] Number of data points in the train set: 354, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.669492 -> initscore=0.705886\n",
      "[LightGBM] [Info] Start training from score 0.705886\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 236, number of negative: 119\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000117 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 767\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.664789 -> initscore=0.684708\n",
      "[LightGBM] [Info] Start training from score 0.684708\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 237, number of negative: 118\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000151 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 741\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.667606 -> initscore=0.697376\n",
      "[LightGBM] [Info] Start training from score 0.697376\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 238, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000158 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 764\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.670423 -> initscore=0.710097\n",
      "[LightGBM] [Info] Start training from score 0.710097\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 237, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000149 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 631\n",
      "[LightGBM] [Info] Number of data points in the train set: 354, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.669492 -> initscore=0.705886\n",
      "[LightGBM] [Info] Start training from score 0.705886\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 236, number of negative: 119\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000139 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 662\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.664789 -> initscore=0.684708\n",
      "[LightGBM] [Info] Start training from score 0.684708\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 237, number of negative: 118\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000116 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 637\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.667606 -> initscore=0.697376\n",
      "[LightGBM] [Info] Start training from score 0.697376\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 238, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000141 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 659\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.670423 -> initscore=0.710097\n",
      "[LightGBM] [Info] Start training from score 0.710097\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 237, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000141 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 729\n",
      "[LightGBM] [Info] Number of data points in the train set: 354, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.669492 -> initscore=0.705886\n",
      "[LightGBM] [Info] Start training from score 0.705886\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 236, number of negative: 119\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000139 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 757\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.664789 -> initscore=0.684708\n",
      "[LightGBM] [Info] Start training from score 0.684708\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 237, number of negative: 118\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000137 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 736\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.667606 -> initscore=0.697376\n",
      "[LightGBM] [Info] Start training from score 0.697376\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 238, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000172 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 756\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.670423 -> initscore=0.710097\n",
      "[LightGBM] [Info] Start training from score 0.710097\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 237, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000395 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 730\n",
      "[LightGBM] [Info] Number of data points in the train set: 354, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.669492 -> initscore=0.705886\n",
      "[LightGBM] [Info] Start training from score 0.705886\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 236, number of negative: 119\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000151 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 760\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.664789 -> initscore=0.684708\n",
      "[LightGBM] [Info] Start training from score 0.684708\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 237, number of negative: 118\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000134 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 736\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.667606 -> initscore=0.697376\n",
      "[LightGBM] [Info] Start training from score 0.697376\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 238, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000151 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 756\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.670423 -> initscore=0.710097\n",
      "[LightGBM] [Info] Start training from score 0.710097\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 237, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000202 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 733\n",
      "[LightGBM] [Info] Number of data points in the train set: 354, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.669492 -> initscore=0.705886\n",
      "[LightGBM] [Info] Start training from score 0.705886\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 236, number of negative: 119\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000137 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.664789 -> initscore=0.684708\n",
      "[LightGBM] [Info] Start training from score 0.684708\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 237, number of negative: 118\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000150 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 740\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.667606 -> initscore=0.697376\n",
      "[LightGBM] [Info] Start training from score 0.697376\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 238, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000129 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 760\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.670423 -> initscore=0.710097\n",
      "[LightGBM] [Info] Start training from score 0.710097\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 237, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000159 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 738\n",
      "[LightGBM] [Info] Number of data points in the train set: 354, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.669492 -> initscore=0.705886\n",
      "[LightGBM] [Info] Start training from score 0.705886\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 236, number of negative: 119\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000110 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 768\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.664789 -> initscore=0.684708\n",
      "[LightGBM] [Info] Start training from score 0.684708\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 237, number of negative: 118\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000149 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 743\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.667606 -> initscore=0.697376\n",
      "[LightGBM] [Info] Start training from score 0.697376\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 238, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000104 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 764\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.670423 -> initscore=0.710097\n",
      "[LightGBM] [Info] Start training from score 0.710097\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 237, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000151 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 744\n",
      "[LightGBM] [Info] Number of data points in the train set: 354, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.669492 -> initscore=0.705886\n",
      "[LightGBM] [Info] Start training from score 0.705886\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 236, number of negative: 119\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000106 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 775\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.664789 -> initscore=0.684708\n",
      "[LightGBM] [Info] Start training from score 0.684708\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 237, number of negative: 118\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000181 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 750\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.667606 -> initscore=0.697376\n",
      "[LightGBM] [Info] Start training from score 0.697376\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 238, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000147 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 772\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.670423 -> initscore=0.710097\n",
      "[LightGBM] [Info] Start training from score 0.710097\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 237, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000117 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 745\n",
      "[LightGBM] [Info] Number of data points in the train set: 354, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.669492 -> initscore=0.705886\n",
      "[LightGBM] [Info] Start training from score 0.705886\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 236, number of negative: 119\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000142 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 775\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.664789 -> initscore=0.684708\n",
      "[LightGBM] [Info] Start training from score 0.684708\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 237, number of negative: 118\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000114 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 750\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.667606 -> initscore=0.697376\n",
      "[LightGBM] [Info] Start training from score 0.697376\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 238, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000137 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 772\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.670423 -> initscore=0.710097\n",
      "[LightGBM] [Info] Start training from score 0.710097\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 237, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000159 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 725\n",
      "[LightGBM] [Info] Number of data points in the train set: 354, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.669492 -> initscore=0.705886\n",
      "[LightGBM] [Info] Start training from score 0.705886\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 236, number of negative: 119\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000136 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 754\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.664789 -> initscore=0.684708\n",
      "[LightGBM] [Info] Start training from score 0.684708\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 237, number of negative: 118\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000139 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 732\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.667606 -> initscore=0.697376\n",
      "[LightGBM] [Info] Start training from score 0.697376\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 238, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000250 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 751\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.670423 -> initscore=0.710097\n",
      "[LightGBM] [Info] Start training from score 0.710097\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 237, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000161 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 750\n",
      "[LightGBM] [Info] Number of data points in the train set: 354, number of used features: 31\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.669492 -> initscore=0.705886\n",
      "[LightGBM] [Info] Start training from score 0.705886\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 236, number of negative: 119\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000104 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 781\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 31\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.664789 -> initscore=0.684708\n",
      "[LightGBM] [Info] Start training from score 0.684708\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 237, number of negative: 118\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000146 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 756\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 31\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.667606 -> initscore=0.697376\n",
      "[LightGBM] [Info] Start training from score 0.697376\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 238, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000144 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 778\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 31\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.670423 -> initscore=0.710097\n",
      "[LightGBM] [Info] Start training from score 0.710097\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 237, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000160 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 750\n",
      "[LightGBM] [Info] Number of data points in the train set: 354, number of used features: 31\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.669492 -> initscore=0.705886\n",
      "[LightGBM] [Info] Start training from score 0.705886\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 236, number of negative: 119\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000126 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 781\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 31\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.664789 -> initscore=0.684708\n",
      "[LightGBM] [Info] Start training from score 0.684708\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 237, number of negative: 118\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000116 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 756\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 31\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.667606 -> initscore=0.697376\n",
      "[LightGBM] [Info] Start training from score 0.697376\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 238, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000154 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 778\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 31\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.670423 -> initscore=0.710097\n",
      "[LightGBM] [Info] Start training from score 0.710097\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 237, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000163 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 745\n",
      "[LightGBM] [Info] Number of data points in the train set: 354, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.669492 -> initscore=0.705886\n",
      "[LightGBM] [Info] Start training from score 0.705886\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 236, number of negative: 119\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000165 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 776\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.664789 -> initscore=0.684708\n",
      "[LightGBM] [Info] Start training from score 0.684708\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 237, number of negative: 118\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000145 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 751\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.667606 -> initscore=0.697376\n",
      "[LightGBM] [Info] Start training from score 0.697376\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 238, number of negative: 117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000143 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 773\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.670423 -> initscore=0.710097\n",
      "[LightGBM] [Info] Start training from score 0.710097\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x2000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# extract a sample of the data\n",
    "sample_df = combined_df.sample(frac=0.01, random_state=0)\n",
    "\n",
    "# define the validation scheme\n",
    "cv = KFold(n_splits=4, shuffle=False, random_state=None) # Don't shuffle to keep the time split split validation\n",
    "\n",
    "# define the binary target and the features\n",
    "dataset = Dataset(df=sample_df, target=\"is_attack\", features=[col for col in combined_df.columns if col != \"is_attack\"])\n",
    "\n",
    "# define the validation scheme and scorer. The default model is LightGBM\n",
    "lofo_imp = LOFOImportance(dataset, cv=cv, scoring=\"roc_auc\")\n",
    "\n",
    "# get the mean and standard deviation of the importances in pandas format\n",
    "importance_df = lofo_imp.get_importance()\n",
    "\n",
    "# plot the means and standard deviations of the importances\n",
    "plot_importance(importance_df, figsize=(12, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
